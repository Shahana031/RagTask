{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DuckDB table 'students' loaded directly from CSV!\n",
      "You :what is the total count of students?\n",
      " Detected Intent: ignore\n",
      "Assistant: I'm here to answer questions about the student dataset. Could you ask something related to that?\n",
      "You :who scored more than 3.5 gpa?\n",
      " Detected Intent: numeric\n",
      " SQL query: SELECT * FROM students WHERE GPA > 3.5;\n",
      "Assistant: The following students scored more than a 3.5 GPA:\n",
      "\n",
      "1. **Ananya Sharma**  \n",
      "   - Department: Computer Science  \n",
      "   - Grade: A+  \n",
      "   - GPA: 3.90  \n",
      "   - Feedback: Ananya consistently excels in AI-related projects and leads her team effectively.\n",
      "\n",
      "2. **Sneha Rao**  \n",
      "   - Department: Electronics  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.70  \n",
      "   - Feedback: Sneha has a deep understanding of microcontrollers and circuit simulation.\n",
      "\n",
      "3. **Diya Thomas**  \n",
      "   - Department: Computer Science  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.80  \n",
      "   - Feedback: Diya is outstanding in Python programming and debugging complex code.\n",
      "\n",
      "4. **Meera Joseph**  \n",
      "   - Department: Information Technology  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.90  \n",
      "   - Feedback: Meera is proactive in web development and machine learning competitions.\n",
      "\n",
      "5. **Karthik Menon**  \n",
      "   - Department: Computer Science  \n",
      "   - Grade: A+  \n",
      "   - GPA: 3.95  \n",
      "   - Feedback: Karthik has exceptional problem-solving skills and works efficiently in AI models.\n",
      "\n",
      "6. **Varun Das**  \n",
      "   - Department: Computer Science  \n",
      "   - Grade: A+  \n",
      "   - GPA: 3.90  \n",
      "   - Feedback: Varun has developed an excellent chatbot using OpenAI APIs.\n",
      "\n",
      "7. **Sachin Verma**  \n",
      "   - Department: Mechanical  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.80  \n",
      "   - Feedback: Sachin excels in mechanical design and team coordination.\n",
      "\n",
      "8. **Riya Nair**  \n",
      "   - Department: Information Technology  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.80  \n",
      "   - Feedback: Riya built a web dashboard for student analytics using Streamlit.\n",
      "\n",
      "9. **Alisha Dsouza**  \n",
      "   - Department: Computer Science  \n",
      "   - Grade: A  \n",
      "   - GPA: 3.80  \n",
      "   - Feedback: Alisha contributes effectively in group coding challenges.\n",
      "\n",
      "10. **Anjali Menon**  \n",
      "    - Department: Information Technology  \n",
      "    - Grade: A+  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Anjali has a strong grasp of APIs and backend frameworks.\n",
      "\n",
      "11. **Shreya Rao**  \n",
      "    - Department: Computer Science  \n",
      "    - Grade: A  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Shreya excels in machine learning algorithms and data analysis.\n",
      "\n",
      "12. **Kiran Thomas**  \n",
      "    - Department: Computer Science  \n",
      "    - Grade: A+  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Kiran has built a facial recognition app using deep learning.\n",
      "\n",
      "13. **Roshni Ramesh**  \n",
      "    - Department: Information Technology  \n",
      "    - Grade: A  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Roshni actively participates in hackathons and builds efficient apps.\n",
      "\n",
      "14. **Keerthi Nair**  \n",
      "    - Department: Information Technology  \n",
      "    - Grade: A+  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Keerthi specializes in frontend and UX design.\n",
      "\n",
      "15. **Vineet Jain**  \n",
      "    - Department: Computer Science  \n",
      "    - Grade: A+  \n",
      "    - GPA: 3.90  \n",
      "    - Feedback: Vineet built a mini recommendation system using LangChain.\n",
      "\n",
      "16. **Priya Sharma**  \n",
      "    - Department: Information Technology  \n",
      "    - Grade: A+  \n",
      "    - GPA: 3.95  \n",
      "    - Feedback: Priya excels in API development and AI-based web solutions. \n",
      "\n",
      "These students have demonstrated exceptional academic performance with GPAs above 3.5.\n",
      "You :exit\n",
      "Assistant: Goodbye! \n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict,List\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "csv_path = \"students.csv\"\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "#with this ‚Äî DuckDB reads CSV natively\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE students AS\n",
    "    SELECT * FROM read_csv_auto('{csv_path}', header=True)\n",
    "\"\"\")\n",
    "\n",
    "print(\" DuckDB table 'students' loaded directly from CSV!\")\n",
    "\n",
    "\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `students`.\n",
    "\n",
    "Table name: students  \n",
    "Columns and their meanings:\n",
    "- StudentID: Unique ID of the student (integer)\n",
    "- Name: Student's full name (text)\n",
    "- Department: Department of study (e.g., Computer Science, Electrical, Mechanical)\n",
    "- Grade: Academic grade (A+, A, A-, B+, etc.)\n",
    "- GPA: Grade Point Average (numeric, e.g., 3.8)\n",
    "- Feedback: Text description of the student's performance and expertise.\n",
    "\n",
    "Sample data:\n",
    "1 | Alice | Computer Science | A | 3.9 | Excellent in IoT and AI projects\n",
    "2 | Bob | Electrical | B+ | 3.4 | Good in circuit design and teamwork\n",
    "3 | Carol | Mechanical | A- | 3.7 | Great at robotics and embedded systems\n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS:\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for numeric or structured filters.  \n",
    "   Examples:\n",
    "   - GPA > 3.8  \n",
    "   - Grade = 'A'  \n",
    "   - Department = 'Computer Science' when asked to list the student's department\n",
    "\n",
    "2. **Do NOT** generate or include text-based or descriptive filters  \n",
    "   such as expertise, feedback content, interests, or skills (e.g., ‚ÄúIoT‚Äù, ‚ÄúAI‚Äù, ‚Äúleadership‚Äù).  \n",
    "   Those are handled separately by another retriever system \n",
    "\n",
    "3. Use the correct table name `students` and column names exactly as given.\n",
    "\n",
    "4. Never hallucinate new columns or tables.\n",
    "\n",
    "5. Return only the SQL query ‚Äî no markdown, explanations, or additional commentary.\n",
    "\n",
    "\n",
    "\n",
    "Example valid queries:\n",
    "- SELECT Name, GPA FROM students WHERE GPA > 3.8;\n",
    "- SELECT * FROM students WHERE Department = 'Computer Science' AND Grade = 'A';\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path=csv_path, encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(texts, embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    intent : str\n",
    "    context : List[str]\n",
    "    answer:str\n",
    "   \n",
    "   \n",
    "def intent_node(state: GraphState):\n",
    "    \"\"\"Use LLM to classify query intent\"\"\"\n",
    "    query = state[\"question\"]\n",
    "    intent_prompt = f\"\"\"\n",
    "        You are an intent classifier for user questions over a student dataset.\n",
    "    The table contains columns: StudentID, Name, Department, Grade, GPA, Feedback.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if it involves:\n",
    "    - filters or comparisons on structured fields like Department, Grade, GPA, or StudentID\n",
    "    - examples: \"List students in Computer Science\", \"Show students with Grade A\", \"Who has GPA > 3.5\"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if it involves open-ended descriptions, expertise, or meanings inside text fields like Feedback\n",
    "    - examples: \"Who is good at AI?\", \"Which student has leadership skills?\"\n",
    "\n",
    "    3. \"hybrid\" ‚Üí if it mixes both structured filters and descriptive parts\n",
    "    - example: \"List students in Computer Science who are good at AI\"\n",
    "\n",
    "    4. \"greet\" ‚Üí greetings like \"Hi\", \"Hello\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí if it's unrelated to student data\n",
    "\n",
    "    Question: {query}\n",
    "    Return only one word : : numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\" Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: GraphState):\n",
    "    state[\"answer\"] = \"Hello! üëã How can I assist you with the student data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: GraphState):\n",
    "    state[\"answer\"] = \"I'm here to answer questions about the student dataset. Could you ask something related to that?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def duckdb_node(state: GraphState):\n",
    "    \"\"\"Numeric / structured question handler with natural output\"\"\"\n",
    "    query = state[\"question\"]\n",
    "    try:\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # Clean SQL\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "            .replace(\"```\", \"\")\n",
    "            .replace(\"`\", \"\")\n",
    "            .replace(\"SQL:\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "\n",
    "        print(f\" SQL query: {sql_query}\")\n",
    "\n",
    "        # Execute SQL on DuckDB\n",
    "        result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # Convert all rows to text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # LLM to summarize results naturally\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a clear and complete natural language response that lists all relevant names or details.\n",
    "        Do not skip or summarize results.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def retriever_node(state: GraphState):\n",
    "    \"\"\"Semantic / descriptive question handler\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = retriever.invoke(question)\n",
    "        pairs = [(question, doc.page_content) for doc in retrieved_chunks]\n",
    "       \n",
    "        top_docs = retrieved_chunks[:3]\n",
    "        context = \"\\n\".join([doc.page_content for doc in top_docs])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content\n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {str(e)}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def hybrid_node(state: GraphState):\n",
    "    \"\"\"Handles hybrid queries by splitting into numeric & semantic sub-questions\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        # Step 1Ô∏è: Ask LLM to split the hybrid query into numeric and semantic subparts\n",
    "        split_prompt = f\"\"\"\n",
    "            Split the user query into numeric and semantic parts.\n",
    "        - Numeric parts are those answerable via SQL (count, average, filter, etc.).\n",
    "        - Semantic parts are descriptive (skills, feedback, comments, etc.).\n",
    "        - If there are multiple sub-questions, list them in an array.\n",
    "\n",
    "        Return clean JSON like:\n",
    "        {{\n",
    "            \"numeric\": \"subquestion for numeric logic\",\n",
    "            \"semantic\": \"subquestion for semantic logic\"\n",
    "        }}\n",
    "\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\" Split result:\", split_result)\n",
    "\n",
    "        import json\n",
    "        try:\n",
    "            #  Clean any code block wrappers before parsing\n",
    "            split_result = (\n",
    "                split_result.replace(\"```json\", \"\")\n",
    "                            .replace(\"```\", \"\")\n",
    "                            .strip()\n",
    "            )\n",
    "\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part = \"\"\n",
    "            semantic_part = \"\"\n",
    "            print(\" LLM didn't return valid JSON ‚Äî skipping split.\")\n",
    "\n",
    "        # Step 2Ô∏è: Route the numeric part to duckdb_node\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            print(f\" Sending numeric part to duckdb_node: {numeric_part}\")\n",
    "            temp_state = {\"question\": numeric_part}\n",
    "            temp_state = {\n",
    "                \"question\": numeric_part,\n",
    "                \"inttent\": \"\",\n",
    "                \"context\": [],\n",
    "                \"answer\": \"\"\n",
    "        }\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "\n",
    "        # Step 3Ô∏è: Route the semantic part to retriever_node\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            print(f\" Sending semantic part to retriever_node: {semantic_part}\")\n",
    "            temp_state = {\"question\": semantic_part}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "\n",
    "        # Step 4Ô∏è: Merge both results using LLM\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight:\n",
    "        {numeric_answer}\n",
    "\n",
    "        Semantic insight:\n",
    "        {semantic_answer}\n",
    "\n",
    "        Combine these into a single, clear and concise final answer.\n",
    "        \"\"\"\n",
    "        final_answer = llm.invoke(combine_prompt).content.strip()\n",
    "        print(\" Final answer:\", final_answer)\n",
    "\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error in hybrid node: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "        \"answer\": \"retriever\"  \n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        \n",
    "        print(f\"You :{user_input}\")\n",
    "    \n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Assistant: Goodbye! \")\n",
    "            break\n",
    "\n",
    "        result = app.invoke({\"question\": user_input})\n",
    "        print(f\"Assistant: {result['answer']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
