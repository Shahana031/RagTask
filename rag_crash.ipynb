{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "from sqlglot import parse_one\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ===== IMPORTANT: Use new Chroma package =====\n",
    "# Run: pip install langchain-chroma\n",
    "try:\n",
    "    from langchain_chroma import Chroma\n",
    "    print(\"‚úÖ Using langchain-chroma (recommended)\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è langchain-chroma not found. Installing...\")\n",
    "    print(\"Please run: pip install langchain-chroma\")\n",
    "    print(\"Then restart the kernel and run again.\")\n",
    "    raise ImportError(\"Please install langchain-chroma: pip install langchain-chroma\")\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "csv_path = r\"D:\\RAG Task\\Client_Shipment_Orders.csv\"\n",
    "db_path = r\"D:\\RAG Task\\orders.duckdb\"\n",
    "persist_directory = r\"D:\\RAG Task\\chroma_db\"  # Separate folder for Chroma\n",
    "collection_name = \"shipment_orders\"\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "\n",
    "# ===== STEP 1: DATABASE SETUP =====\n",
    "print(\"üìä Setting up DuckDB database...\")\n",
    "with duckdb.connect(db_path) as con:\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS orders AS\n",
    "        SELECT * FROM read_csv_auto('{csv_path}');\n",
    "    \"\"\")\n",
    "print(\"‚úÖ Database ready!\")\n",
    "\n",
    "# ===== STEP 2: VECTOR STORE SETUP (with proper caching) =====\n",
    "def setup_vector_store():\n",
    "    \"\"\"Setup or load existing vector store to avoid recreation\"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    # Create persist directory if it doesn't exist\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "    \n",
    "    # Check if vector store already exists\n",
    "    chroma_db_exists = os.path.exists(os.path.join(persist_directory, \"chroma.sqlite3\"))\n",
    "    \n",
    "    if chroma_db_exists:\n",
    "        try:\n",
    "            print(\"üîç Loading existing vector store...\")\n",
    "            vector_store = Chroma(\n",
    "                persist_directory=persist_directory,\n",
    "                embedding_function=embeddings,\n",
    "                collection_name=collection_name\n",
    "            )\n",
    "            \n",
    "            # Verify it has data\n",
    "            collection_count = vector_store._collection.count()\n",
    "            if collection_count > 0:\n",
    "                print(f\"‚úÖ Loaded existing vector store with {collection_count} documents\")\n",
    "                return vector_store, embeddings\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Vector store is empty, will create new one\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading vector store: {e}\")\n",
    "            print(\"Creating new vector store...\")\n",
    "    else:\n",
    "        print(\"üìù No existing vector store found, creating new one...\")\n",
    "    \n",
    "    # Create new vector store\n",
    "    print(\"üìÑ Loading CSV and generating chunks...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"   Loaded {len(df)} rows\")\n",
    "    \n",
    "    # Generate chunks\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (index + 1) % 100 == 0:\n",
    "            print(f\"   Processed {index + 1}/{len(df)} rows...\", end='\\r')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(chunks)} labelled chunks\")\n",
    "    \n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "    \n",
    "    print(\"üîÑ Creating embeddings and vector store (this may take a few minutes)...\")\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    print(\"‚úÖ Vector store created and persisted!\")\n",
    "    \n",
    "    # Clean up memory\n",
    "    del df, chunks, documents\n",
    "    \n",
    "    return vector_store, embeddings\n",
    "\n",
    "# Setup vector store\n",
    "vector_store, embeddings = setup_vector_store()\n",
    "\n",
    "# ===== STEP 3: SETUP RETRIEVERS =====\n",
    "print(\"üîß Setting up retrievers...\")\n",
    "\n",
    "# For BM25, load a sample or use lightweight approach\n",
    "print(\"   Loading documents for BM25...\")\n",
    "with duckdb.connect(db_path) as con:\n",
    "    # Use LIMIT to avoid memory issues\n",
    "    sample_size = min(1000, vector_store._collection.count())\n",
    "    df_sample = con.execute(f\"SELECT * FROM orders LIMIT {sample_size}\").fetchdf()\n",
    "\n",
    "chunks_for_bm25 = []\n",
    "for index, row in df_sample.iterrows():\n",
    "    text = \" \".join([f\"{col}: {row[col]}\" for col in df_sample.columns])\n",
    "    chunks_for_bm25.append(text)\n",
    "\n",
    "documents_for_bm25 = [Document(page_content=chunk) for chunk in chunks_for_bm25]\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents_for_bm25)\n",
    "keyword_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, keyword_retriever],\n",
    "    weights=[0.6, 0.4]\n",
    ")\n",
    "\n",
    "# Clean up temporary data\n",
    "del df_sample, chunks_for_bm25, documents_for_bm25\n",
    "\n",
    "print(\"‚úÖ Retrievers ready!\")\n",
    "\n",
    "# ===== LLM SETUP =====\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ===== SQL SYSTEM PROMPT =====\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "TABLE INFORMATION:\n",
    "Table: orders  \n",
    "Columns: Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ), Total Price (‚Çπ),\n",
    "Order Date, Delivery Date, Status\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Generate SQL queries ONLY for structured/numeric filters\n",
    "2. Use exact column names with quotes: \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "3. Return ONLY the SQL query - no markdown, comments, or explanations\n",
    "4. SAFETY: Only SELECT queries allowed (no INSERT, UPDATE, DELETE, DROP, etc.)\n",
    "5. Use LOWER() for case-insensitive text matching\n",
    "6. For \"highest\" queries, use subqueries to avoid grouping errors\n",
    "\n",
    "Example for \"highest purchase\":\n",
    "SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "FROM orders\n",
    "WHERE \"Total Price (‚Çπ)\" = (SELECT MAX(\"Total Price (‚Çπ)\") FROM orders);\n",
    "\"\"\"\n",
    "\n",
    "# ===== STATE GRAPH =====\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    intent_prompt = f\"\"\"\n",
    "    Classify this query about an Orders dataset as ONE word:\n",
    "    - numeric: count, sum, statistics, filters\n",
    "    - semantic: descriptive, interpretive questions\n",
    "    - hybrid: both numeric and semantic\n",
    "    - greet: greetings\n",
    "    - ignore: unrelated\n",
    "    \n",
    "    Question: {question}\n",
    "    Answer with ONE word only:\n",
    "    \"\"\"\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about orders. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks[:5]])  # Limit context\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error in retrieval: {e}\"\n",
    "        print(f\"‚ùå Retriever error: {e}\")\n",
    "    return state\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    \n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries allowed.\"\n",
    "        return state\n",
    "    \n",
    "    forbidden = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden):\n",
    "        state[\"validation_error\"] = \"‚ùå Unsafe SQL operation detected.\"\n",
    "        return state\n",
    "    \n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column: '{match}'.\"\n",
    "            return state\n",
    "    \n",
    "    state[\"validation_error\"] = None\n",
    "    return state\n",
    "\n",
    "def duckdb_node(state: dict):\n",
    "    query = state[\"question\"]\n",
    "    try:\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").replace(\"`\", \"\").strip()\n",
    "        \n",
    "        print(f\"üß† Generated SQL: {sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "        \n",
    "        # Validate syntax\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "        except Exception as e:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error: {e}\"\n",
    "            return state\n",
    "        \n",
    "        # Validate safety\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "        \n",
    "        # Execute\n",
    "        with duckdb.connect(db_path) as con:\n",
    "            result_df = con.execute(sql_query).fetchdf()\n",
    "        \n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "        \n",
    "        result_text = result_df.to_string(index=False)\n",
    "        summary_prompt = f\"User asked: {query}\\n\\nSQL result:\\n{result_text}\\n\\nProvide a clear, natural explanation:\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing query: {str(e)}\"\n",
    "        print(f\"‚ùå DuckDB error: {e}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def hybrid_node(state: dict):\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"üîÄ Processing hybrid query: {question}\")\n",
    "        \n",
    "        split_prompt = f\"\"\"Split this query into numeric and semantic parts.\n",
    "        Return ONLY valid JSON:\n",
    "        {{\"numeric\": \"numeric question part\", \"semantic\": \"semantic question part\", \"dependent\": true/false}}\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        parsed = json.loads(split_result)\n",
    "        \n",
    "        numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "        semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "        dependent = parsed.get(\"dependent\", False)\n",
    "        \n",
    "        print(f\"   Numeric: {numeric_part}\")\n",
    "        print(f\"   Semantic: {semantic_part}\")\n",
    "        print(f\"   Dependent: {dependent}\")\n",
    "        \n",
    "        # Get numeric answer\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            temp = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_answer = duckdb_node(temp).get(\"answer\", \"\")\n",
    "        \n",
    "        # Get semantic answer (if independent)\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part and not dependent:\n",
    "            temp = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_answer = retriever_node(temp).get(\"answer\", \"\")\n",
    "        \n",
    "        # Combine results\n",
    "        combine_prompt = f\"\"\"Original question: {question}\n",
    "        \n",
    "        Numeric insight: {numeric_answer or 'None'}\n",
    "        Semantic insight: {semantic_answer or 'None'}\n",
    "        \n",
    "        Provide a unified, natural answer that addresses the original question:\n",
    "        \"\"\"\n",
    "        \n",
    "        final_answer = llm.invoke(combine_prompt).content.strip()\n",
    "        state[\"answer\"] = final_answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error in hybrid processing: {str(e)}\"\n",
    "        print(f\"‚ùå Hybrid error: {e}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# ===== BUILD GRAPH =====\n",
    "print(\"üèóÔ∏è Building state graph...\")\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "print(\"‚úÖ Graph compiled successfully!\")\n",
    "\n",
    "# ===== MAIN LOOP =====\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ Smart Query Assistant Ready!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Type 'exit' or 'quit' to end the session.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Assistant: Goodbye üëã\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            result = app.invoke({\"question\": user_input})\n",
    "            print(f\"\\nAssistant: {result['answer']}\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nAssistant: Goodbye üëã\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c96ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 50 labelled chunks for embeddings.\n",
      "‚úÖ Loading existing FAISS index...\n",
      "‚úÖ FAISS index loaded successfully!\n",
      "\n",
      "üöÄ Smart Query Assistant ready! Type 'exit' to quit.\n",
      "\n",
      "You: orders that were delivered on october month and list the product names\n",
      "üéØ Detected Intent: hybrid\n",
      "\n",
      "üîÄ [Hybrid Node] Received question ‚Üí orders that were delivered on october month and list the product names\n",
      "üß© Raw Split Result: {\n",
      "    \"numeric\": \"Find orders that were delivered in October.\",\n",
      "    \"semantic\": \"List the product names associated with those orders.\",\n",
      "    \"dependent\": false\n",
      "}\n",
      "‚úÖ Parsed numeric part: Find orders that were delivered in October.\n",
      "‚úÖ Parsed semantic part: List the product names associated with those orders.\n",
      "üîó Dependency from split: False\n",
      "\n",
      "üß† Dependency Classifier Output: {\n",
      "    \"dependent\": true,\n",
      "    \"reason\": \"The semantic sub-question requires the results of the numeric sub-question to identify which product names to list, as it specifically pertains to the orders delivered in October.\"\n",
      "}\n",
      "‚úÖ Final dependency decision: True\n",
      "\n",
      "üß† Generated SQL query:\n",
      "SELECT *\n",
      "FROM orders\n",
      "WHERE \"Delivery Date\" >= '2025-10-01' AND \"Delivery Date\" < '2025-11-01';\n",
      "‚úÖ SQLGlot syntax check passed.\n",
      "üß© Validating SQL query: SELECT *\n",
      "FROM orders\n",
      "WHERE \"Delivery Date\" >= '2025-10-01' AND \"Delivery Date\" < '2025-11-01';\n",
      "‚úÖ SQL validation passed.\n",
      "\n",
      "üßÆ NUMERIC RESULT (SQL):\n",
      "The SQL query returned a list of orders that were delivered in October. Here‚Äôs a breakdown of the results:\n",
      "\n",
      "1. **Order ID: ORD0009**\n",
      "   - **Client Name:** Scott Mckenzie\n",
      "   - **Email:** msavage@yahoo.com\n",
      "   - **Contact Number:** 044-517-0114x5220\n",
      "   - **Origin:** Tarahaven\n",
      "   - **Destination:** Lake Sarah\n",
      "   - **Product Name:** Wall Tiles\n",
      "   - **Category:** Ceramics\n",
      "   - **Material:** Marble\n",
      "   - **Color:** Beige\n",
      "   - **Quantity:** 36\n",
      "   - **Unit Price:** ‚Çπ13,105\n",
      "   - **Total Price:** ‚Çπ471,780\n",
      "   - **Order Date:** October 7, 2025\n",
      "   - **Delivery Date:** October 14, 2025\n",
      "   - **Status:** Shipped\n",
      "\n",
      "2. **Order ID: ORD0011**\n",
      "   - **Client Name:** Karen Lee\n",
      "   - **Email:** ladams@johnson-gill.com\n",
      "   - **Contact Number:** +1-698-330-4269\n",
      "   - **Origin:** East Troyfort\n",
      "   - **Destination:** West Jamesmouth\n",
      "   - **Product Name:** Bed\n",
      "   - **Category:** Furniture\n",
      "   - **Material:** Ceramic\n",
      "   - **Color:** Brown\n",
      "   - **Quantity:** 40\n",
      "   - **Unit Price:** ‚Çπ21,995\n",
      "   - **Total Price:** ‚Çπ879,800\n",
      "   - **Order Date:** October 14, 2025\n",
      "   - **Delivery Date:** October 29, 2025\n",
      "   - **Status:** Pending\n",
      "\n",
      "3. **Order ID: ORD0012**\n",
      "   - **Client Name:** Eric Barrera\n",
      "   - **Email:** kellymartinez@yahoo.com\n",
      "   - **Contact Number:** 384-769-4319\n",
      "   - **Origin:** North Matthewfurt\n",
      "   - **Destination:** Davidbury\n",
      "   - **Product Name:** Air Conditioner\n",
      "   - **Category:** Appliances\n",
      "   - **Material:** Ceramic\n",
      "   - **Color:** Black\n",
      "   - **Quantity:** 11\n",
      "   - **Unit Price:** ‚Çπ19,221\n",
      "   - **Total Price:** ‚Çπ211,431\n",
      "   - **Order Date:** September 9, 2025\n",
      "   - **Delivery Date:** October 5, 2025\n",
      "   - **Status:** Pending\n",
      "\n",
      "4. **Order ID: ORD0014**\n",
      "   - **Client Name:** Daniel Fowler\n",
      "   - **Email:** jonathansmith@hoffman.com\n",
      "   - **Contact Number:** 5858988889\n",
      "   - **Origin:** New Anthony\n",
      "   - **Destination:** Lake Samantha\n",
      "   - **Product Name:** Dining Table\n",
      "   - **Category:** Furniture\n",
      "   - **Material:** Plastic\n",
      "   - **Color:** Black\n",
      "   - **Quantity:** 39\n",
      "   - **Unit Price:** ‚Çπ1,963\n",
      "   - **Total Price:** ‚Çπ76,557\n",
      "   - **Order Date:** October 2, 2025\n",
      "   - **Delivery Date:** October 12, 2025\n",
      "   - **Status:** Delivered\n",
      "\n",
      "5. **Order ID: ORD0019**\n",
      "   - **Client Name:** James Chapman\n",
      "   - **Email:** fcarpenter@hotmail.com\n",
      "   - **Contact Number:** 2970034873\n",
      "   - **Origin:** Joshuashire\n",
      "   - **Destination:** South Ambershire\n",
      "   - **Product Name:** Curtain\n",
      "   - **Category:** Decor\n",
      "   - **Material:** Ceramic\n",
      "   - **Color:** Black\n",
      "   - **Quantity:** 40\n",
      "   - **Unit Price:** ‚Çπ4,689\n",
      "   - **Total Price:** ‚Çπ187,560\n",
      "   - **Order Date:** October 11, 2025\n",
      "   - **Delivery Date:** October 27, 2025\n",
      "   - **Status:** In Transit\n",
      "\n",
      "6. **Order ID: ORD0027**\n",
      "   - **Client Name:** Cynthia Campbell DDS\n",
      "   - **Email:** xashley@gonzales.biz\n",
      "   - **Contact Number:** +1-545-658-6306\n",
      "   - **Origin:** Woodsside\n",
      "   - **Destination:** Brownside\n",
      "   - **Product Name:** Chair\n",
      "   - **Category:** Furniture\n",
      "   - **Material:** Glass\n",
      "   - **Color:** Brown\n",
      "   - **Quantity:** 37\n",
      "   - **Unit Price:** ‚Çπ15,251\n",
      "   - **Total Price:** ‚Çπ564,287\n",
      "   - **Order Date:** September 19, 2025\n",
      "   - **Delivery Date:** October 17, 2025\n",
      "   - **Status:** Pending\n",
      "\n",
      "7. **Order ID: ORD0028**\n",
      "   - **Client Name:** Luis Wright\n",
      "   - **Email:** pleonard@gmail.com\n",
      "   - **Contact Number:** 8921956244\n",
      "   - **Origin:** Kingside\n",
      "   - **Destination:** Dunnside\n",
      "   - **Product Name:** Microwave\n",
      "   - **Category:** Appliances\n",
      "   - **Material:** Wood\n",
      "   - **Color:** Black\n",
      "   - **Quantity:** 26\n",
      "   - **Unit Price:** ‚Çπ14,427\n",
      "   - **Total Price:** ‚Çπ375,102\n",
      "   - **Order Date:** September 14, 2025\n",
      "   - **Delivery Date:** October 14, 2025\n",
      "   - **Status:** Pending\n",
      "\n",
      "8. **Order ID: ORD0030**\n",
      "   - **Client Name:** Kenneth Johnson\n",
      "   - **Email:** dwarner@yahoo.com\n",
      "   - **Contact Number:** 074-323-3278x50833\n",
      "   - **Origin:** South Angela\n",
      "   - **Destination:** New Jonathanton\n",
      "   - **Product Name:** Floor Tiles\n",
      "   - **Category:** Ceramics\n",
      "   - **Material:** Marble\n",
      "   - **Color:** Black\n",
      "   - **Quantity:** 42\n",
      "   - **Unit Price:** ‚Çπ19,964\n",
      "   - **Total Price:** ‚Çπ838,488\n",
      "   - **Order Date:** September 24, 2025\n",
      "   - **Delivery Date:** October 8, 2025\n",
      "   - **Status:** Shipped\n",
      "\n",
      "9. **Order ID: ORD0035**\n",
      "   - **Client Name:** Michael Roberson\n",
      "   - **Email:** zcampos@sanchez.org\n",
      "   - **Contact Number:** 907.719.2389x99046\n",
      "   - **Origin:** Fisherbury\n",
      "   - **Destination:** Wrightton\n",
      "   - **Product Name:** Bathtub\n",
      "   - **Category:** Ceramics\n",
      "   - **Material:** Wood\n",
      "   - **Color:** Grey\n",
      "   - **Quantity:** 7\n",
      "   - **Unit Price:** ‚Çπ24,155\n",
      "   - **Total Price:** ‚Çπ169,085\n",
      "   - **Order Date:** September 18, 2025\n",
      "   - **Delivery Date:** October 13, 2025\n",
      "   - **Status:** Cancelled\n",
      "\n",
      "10. **Order ID: ORD0045**\n",
      "    - **Client Name:** Barbara Brewer\n",
      "    - **Email:** fgonzalez@hotmail.com\n",
      "    - **Contact Number:** 001-579-665-3908x7242\n",
      "    - **Origin:** Port Kyle\n",
      "    - **Destination:** Lake Danielle\n",
      "    - **Product Name:** Washing Machine\n",
      "    - **Category:** Appliances\n",
      "    - **Material:** Glass\n",
      "    - **Color:** Brown\n",
      "    - **Quantity:** 1\n",
      "    - **Unit Price:** ‚Çπ3,303\n",
      "    - **Total Price:** ‚Çπ3,303\n",
      "    - **Order Date:** October 3, 2025\n",
      "    - **Delivery Date:** October 22, 2025\n",
      "    - **Status:** Shipped\n",
      "\n",
      "In summary, the results include a mix of orders with various statuses, including \"Shipped,\" \"Pending,\" \"In Transit,\" and \"Cancelled.\" Notably, the only order that was successfully delivered in October is from Daniel Fowler (Order ID: ORD0014), which was delivered on October 12, 2025. Other orders are either pending delivery or have been shipped but not yet delivered.\n",
      "\n",
      "üí¨ SEMANTIC RESULT (Retriever):\n",
      "1. Bed\n",
      "2. Washing Machine\n",
      "3. Refrigerator\n",
      "4. Washing Machine\n",
      "5. Microwave\n",
      "6. Bed\n",
      "7. Dining Table\n",
      "8. Bed\n",
      "9. Curtain\n",
      "10. Washing Machine\n",
      "11. Mirror\n",
      "12. Curtain\n",
      "13. Air Conditioner\n",
      "‚úÖ Dependent query detected ‚Äî skipping independent validation step.\n",
      "\n",
      "üß† Combining numeric & semantic results...\n",
      "Assistant: In October, the following products were delivered:\n",
      "\n",
      "1. **Dining Table** (Order ID: ORD0014) - Delivered on October 12, 2025.\n",
      "\n",
      "Additionally, the following products were part of orders that were either pending or shipped but not yet delivered in October:\n",
      "\n",
      "- Bed\n",
      "- Washing Machine\n",
      "- Refrigerator\n",
      "- Microwave\n",
      "- Bed\n",
      "- Dining Table\n",
      "- Bed\n",
      "- Curtain\n",
      "- Washing Machine\n",
      "- Mirror\n",
      "- Curtain\n",
      "- Air Conditioner\n",
      "\n",
      "In summary, the only product successfully delivered in October was the **Dining Table**.\n",
      "\n",
      "You: exit\n",
      "Assistant: Goodbye üëã\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sqlglot import parse_one\n",
    "import json\n",
    "\n",
    "# ‚úÖ Step 1: Define paths\n",
    "csv_path = r\"D:\\RAG Task\\Client_Shipment_Orders.csv\"\n",
    "db_path = r\"D:\\RAG Task\\orders.duckdb\"\n",
    "faiss_index_path = r\"D:\\RAG Task\\faiss_index\"\n",
    "\n",
    "# ‚úÖ Step 2: Create or update database table (runs only once)\n",
    "with duckdb.connect(db_path) as con:\n",
    "    # Create the 'orders' table if not already present\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS orders AS\n",
    "        SELECT * FROM read_csv_auto('{csv_path}');\n",
    "    \"\"\")\n",
    "    # Optional: Refresh data if you've updated CSV\n",
    "    # con.execute(f\"DELETE FROM orders; INSERT INTO orders SELECT * FROM read_csv_auto('{csv_path}');\")\n",
    "\n",
    "# ‚úÖ Step 3: Load DataFrame safely for local use\n",
    "with duckdb.connect(db_path) as con:\n",
    "    df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "# ‚úÖ Step 4: Clean / normalize text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.title()\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "----------------------------------\n",
    "TABLE INFORMATION\n",
    "----------------------------------\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "----------------------------------\n",
    "SAMPLE DATA\n",
    "----------------------------------\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for structured or numeric filters.\n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries based on subjective or descriptive logic\n",
    "   such as reasons for cancellation, customer feedback, or preferences.\n",
    "   These are handled separately by a semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names **exactly as shown**.\n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that do not exist.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, comments, or explanations.\n",
    "\n",
    "6. **SAFETY RULES ‚Äî STRICTLY ENFORCED**\n",
    "   - Never modify or delete data.\n",
    "   - Do not use or suggest `UPDATE`, `DELETE`, `INSERT`, `DROP`, `TRUNCATE`, or `ALTER`.\n",
    "   - Do not create or alter schemas, indexes, or tables.\n",
    "   - Only allow read-only operations:  \n",
    "     `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and aggregate functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`).\n",
    "\n",
    "7. **Case Handling:**  \n",
    "   When matching text values (like product or status), use `LOWER()` to make comparisons case-insensitive.  \n",
    "   Example:  \n",
    "   `WHERE LOWER(\"Product Name\") = LOWER('Toilet Bowl')`\n",
    "\n",
    "8. **Special Handling ‚Äî Highest or Maximum Queries:**  \n",
    "   If the user asks questions like  \n",
    "   *\"Who made the highest purchase?\"*,  \n",
    "   *\"Which client has the largest total?\"*, or  \n",
    "   *\"Top buyer / maximum purchase amount\"*,  \n",
    "   use this pattern to avoid grouping errors:\n",
    "   ```sql\n",
    "   SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "   FROM orders\n",
    "   WHERE \"Total Price (‚Çπ)\" = (\n",
    "       SELECT MAX(\"Total Price (‚Çπ)\") FROM orders\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\"‚úÖ Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "# ‚úÖ Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# ‚úÖ Create or load FAISS vector store\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\"‚úÖ Loading existing FAISS index...\")\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(\n",
    "            faiss_index_path, \n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\"‚úÖ FAISS index loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading FAISS index: {e}\")\n",
    "        print(\"‚úÖ Creating new FAISS index...\")\n",
    "        vector_store = FAISS.from_documents(documents, embeddings)\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        print(\"‚úÖ New FAISS index created and saved!\")\n",
    "else:\n",
    "    print(\"‚úÖ Creating new FAISS index...\")\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(faiss_index_path, exist_ok=True)\n",
    "    vector_store.save_local(faiss_index_path)\n",
    "    print(\"‚úÖ FAISS index created and saved!\")\n",
    "\n",
    "# ‚úÖ Set up retrievers\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, keyword_retriever],\n",
    "    weights=[0.6, 0.4]\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    intent_prompt = f\"\"\"\n",
    "    You are an intent classifier for user questions over an **Orders dataset**.\n",
    "    The table contains the following columns:\n",
    "    Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "    Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "    Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if the query involves structured, measurable, or count-based data.\n",
    "       Examples:\n",
    "       - \"How many orders are pending?\"\n",
    "       - \"What is the total sales amount?\"\n",
    "       - \"Show the average unit price.\"\n",
    "       - \"Count the number of clients.\"\n",
    "       - \"List orders where quantity > 10.\n",
    "       - \"Who made the highest purchase?\"\n",
    "       - \"names of customers who ordered bed \"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if the query involves descriptive or text-based attributes\n",
    "       such true semantic questions, i.e., ones that are descriptive, interpretive, or text-based, not solvable with SQL filters or numbers.\n",
    "T       These rely on understanding meaning, patterns, or unstructured context rather than column values.\n",
    "       Examples:\n",
    "      - Which customers look like regular buyers of furniture?\n",
    "      - Which products are most suitable for modern homes?\n",
    "      - What type of products are popular in Port Mariamouth?\n",
    "      \n",
    "    3. \"hybrid\" ‚Üí if the query mixes both numeric and descriptive components.\n",
    "       Examples:\n",
    "       - What is the total count of clients who bought curtains and Which destination cities frequently receive d√©cor orders?? \n",
    "\n",
    "    4. \"greet\" ‚Üí greetings or conversational openers.\n",
    "       Examples:\n",
    "       - \"Hi\", \"Hello\", \"Good morning\", \"Hey there\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí unrelated or irrelevant to order data.\n",
    "       Examples:\n",
    "       - \"Tell me a joke\", \"What's the time?\", \"Who is the CEO?\"\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Return only one word:\n",
    "    numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\"üß© Validating SQL query: {sql_query}\")\n",
    "\n",
    "    # ‚úÖ 1. Ensure it's a SELECT query\n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚ùå 2. Block dangerous operations\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = (\n",
    "            f\"‚ùå Unsafe SQL operation detected. \"\n",
    "            f\"Keywords like {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # ‚úÖ 3. Validate columns used in SQL (prevent hallucinated fields)\n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column name used: '{match}'.\"\n",
    "            return state\n",
    "\n",
    "    # ‚úÖ 4. Passed all checks\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\"‚úÖ SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "def duckdb_node(state: dict):\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL with SQLGlot before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        # üß† Step 1: Ask LLM to generate SQL\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # üßπ Step 2: Clean LLM formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüß† Generated SQL query:\\n{sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        # ‚úÖ Step 3: Syntax validation using SQLGlot\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "            print(\"‚úÖ SQLGlot syntax check passed.\")\n",
    "        except Exception as parse_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error detected: {parse_err}\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 4: Custom SQL safety validation\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 5: Safe execution inside a local DuckDB context\n",
    "        try:\n",
    "            with duckdb.connect(db_path) as con:\n",
    "                result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "        except Exception as exec_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL execution failed: {exec_err}\"\n",
    "            return state\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 6: Convert results to plain text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # ‚úÖ Step 7: Generate human-readable summary\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping rows or making assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def hybrid_node(state: dict):\n",
    "    \"\"\"Handles hybrid queries (numeric + semantic), with LLM-driven dependency classification and validation.\"\"\"\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "        # 1Ô∏è‚É£ STEP 1 ‚Äî Query Splitting (same as before)\n",
    "        split_prompt = f\"\"\"\n",
    "        You are a **query-splitting assistant** for a hybrid SQL-semantic system.\n",
    "\n",
    "        Analyze the following user query and output valid JSON with:\n",
    "        - \"numeric\": SQL-based measurable part (count, sum, max, etc.)\n",
    "        - \"semantic\": descriptive/contextual part\n",
    "        - \"dependent\": true if semantic depends on numeric; false if both are independent.\n",
    "\n",
    "        Examples:\n",
    "        1Ô∏è‚É£ Dependent ‚Üí \"Who made the highest purchase and how much was it?\"\n",
    "        {{\n",
    "            \"numeric\": \"Find the highest purchase amount and corresponding client name.\",\n",
    "            \"semantic\": \"Who made that purchase and what was the total price?\",\n",
    "            \"dependent\": true\n",
    "        }}\n",
    "\n",
    "        2Ô∏è‚É£ Independent ‚Üí \"What is the total revenue and list all product categories?\"\n",
    "        {{\n",
    "            \"numeric\": \"What is the total revenue?\",\n",
    "            \"semantic\": \"List all product categories.\",\n",
    "            \"dependent\": false\n",
    "        }}\n",
    "\n",
    "        ---\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "        try:\n",
    "            split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "            dependent_from_split = parsed.get(\"dependent\", False)\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part, semantic_part, dependent_from_split = \"\", \"\", False\n",
    "            print(\"‚ö†Ô∏è Invalid JSON in split, skipping split-based dependency flag.\")\n",
    "\n",
    "        print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "        print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "        print(f\"üîó Dependency from split: {dependent_from_split}\")\n",
    "\n",
    "        # 2Ô∏è‚É£ STEP 2 ‚Äî LLM-Guided Dependency Classifier (production-safe)\n",
    "        dependency_prompt = f\"\"\"\n",
    "        You are a query dependency classifier.\n",
    "\n",
    "        Determine if the following sub-questions are logically dependent:\n",
    "        - Numeric sub-question: {numeric_part}\n",
    "        - Semantic sub-question: {semantic_part}\n",
    "\n",
    "        Return JSON:\n",
    "        {{\n",
    "            \"dependent\": true/false,\n",
    "            \"reason\": \"brief explanation\"\n",
    "        }}\n",
    "\n",
    "        Example:\n",
    "        {{\n",
    "            \"dependent\": true,\n",
    "            \"reason\": \"The semantic sub-question refers to the same entity as the numeric result.\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        dependency_result = llm.invoke(dependency_prompt).content.strip()\n",
    "        print(\"\\nüß† Dependency Classifier Output:\", dependency_result)\n",
    "\n",
    "        try:\n",
    "            dependency_result = dependency_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            dep_parsed = json.loads(dependency_result)\n",
    "            dependent = dep_parsed.get(\"dependent\", dependent_from_split)\n",
    "        except json.JSONDecodeError:\n",
    "            dependent = dependent_from_split\n",
    "            print(\"‚ö†Ô∏è Could not parse dependency JSON ‚Äî using split result fallback.\")\n",
    "\n",
    "        print(f\"‚úÖ Final dependency decision: {dependent}\")\n",
    "\n",
    "        # 3Ô∏è‚É£ STEP 3 ‚Äî Numeric Answer (SQL via DuckDB)\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüßÆ NUMERIC RESULT (SQL):\")\n",
    "            print(numeric_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No numeric part found.\")\n",
    "\n",
    "        # 4Ô∏è‚É£ STEP 4 ‚Äî Semantic Answer (Retriever / Hybrid LLM)\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüí¨ SEMANTIC RESULT (Retriever):\")\n",
    "            print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No semantic part found.\")\n",
    "\n",
    "        # 5Ô∏è‚É£ STEP 5 ‚Äî Validation (only for independent queries)\n",
    "        if not dependent and numeric_answer and semantic_answer:\n",
    "            validation_prompt = f\"\"\"\n",
    "            Validate factual consistency between two independent results.\n",
    "\n",
    "            Numeric result:\n",
    "            {numeric_answer}\n",
    "\n",
    "            Semantic result:\n",
    "            {semantic_answer}\n",
    "\n",
    "            If both address unrelated aspects (e.g., total vs list), mark as consistent.\n",
    "\n",
    "            Reply only in JSON:\n",
    "            {{\n",
    "                \"is_consistent\": true/false,\n",
    "                \"issues\": \"briefly describe inconsistencies\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            validation = llm.invoke(validation_prompt).content.strip()\n",
    "            print(\"\\nüîç Validation result:\", validation)\n",
    "\n",
    "            try:\n",
    "                validation_json = json.loads(validation.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "                consistent = validation_json.get(\"is_consistent\", True)\n",
    "            except:\n",
    "                consistent = True  # fallback\n",
    "\n",
    "            if not consistent:\n",
    "                print(\"‚ö†Ô∏è Inconsistency detected ‚Äî regenerating semantic answer with numeric context.\")\n",
    "                retry_prompt = f\"\"\"\n",
    "                User question: {question}\n",
    "\n",
    "                Numeric (SQL) result:\n",
    "                {numeric_answer}\n",
    "\n",
    "                Previous semantic result:\n",
    "                {semantic_answer}\n",
    "\n",
    "                Generate a consistent unified answer that aligns with the numeric facts.\n",
    "                \"\"\"\n",
    "                semantic_answer = llm.invoke(retry_prompt).content.strip()\n",
    "                print(\"\\n‚ôªÔ∏è RETRIED SEMANTIC ANSWER:\")\n",
    "                print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚úÖ Dependent query detected ‚Äî skipping independent validation step.\")\n",
    "\n",
    "        # 6Ô∏è‚É£ STEP 6 ‚Äî Combine Results (context-aware merge)\n",
    "        print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight:\n",
    "        {numeric_answer or \"None\"}\n",
    "\n",
    "        Semantic insight:\n",
    "        {semantic_answer or \"None\"}\n",
    "\n",
    "        Combine both into a single, concise, factual answer.\n",
    "        If dependent, mention both the entity and its numeric value clearly.\n",
    "        \"\"\"\n",
    "        combined_response = llm.invoke(combine_prompt)\n",
    "        final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "        state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            print(f\"You: {user_input}\")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Assistant: Goodbye üëã\")\n",
    "                break\n",
    "\n",
    "            result = app.invoke({\"question\": user_input})\n",
    "            print(f\"Assistant: {result['answer']}\\n\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistant: Goodbye üëã\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            print(\"Please try again with a different question.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
