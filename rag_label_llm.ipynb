{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85724867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever,EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "\n",
    "csv_path = \"Client_Shipment_Orders.csv\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "#with this ‚Äî DuckDB reads CSV natively\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE orders AS\n",
    "    SELECT * FROM read_csv_auto('{csv_path}', header=True)\n",
    "\"\"\")\n",
    "\n",
    "print(\" DuckDB table 'orders' loaded directly from CSV!\")\n",
    "\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "\n",
    "TABLE INFORMATION\n",
    "\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "\n",
    "SAMPLE DATA\n",
    "\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "\n",
    "INSTRUCTIONS\n",
    "\n",
    "1. Generate SQL queries **only** for structured or numeric filters.  \n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by specific columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries that rely on descriptive, subjective, or semantic attributes  \n",
    "   such as client feedback, reasons for cancellation, customer sentiment, or preferences.  \n",
    "   These are handled separately by another semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names exactly as given.  \n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that don‚Äôt exist in the schema.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, explanations, or commentary.\n",
    "\n",
    "6.\n",
    "Do not modify, insert, delete, or drop any data or tables.\n",
    "\n",
    "Do not perform schema changes such as ALTER, TRUNCATE, or CREATE.\n",
    "\n",
    "Do not use UPDATE, INSERT, DELETE, DROP, TRUNCATE, or ALTER statements.\n",
    "\n",
    "Only use safe read-only operations such as:\n",
    "\n",
    "SELECT\n",
    "\n",
    "WHERE, GROUP BY, ORDER BY, LIMIT\n",
    "\n",
    "Aggregation functions (COUNT, SUM, AVG, MIN, MAX)\n",
    "\n",
    "Never execute or suggest any operation that could change the database.\n",
    "\n",
    "----------------------------------\n",
    "Example valid queries:\n",
    "----------------------------------\n",
    "- SELECT COUNT(DISTINCT \"Client Name\") AS total_clients FROM orders;\n",
    "- SELECT SUM(\"Total Price (‚Çπ)\") AS total_sales FROM orders WHERE LOWER(Status) = 'delivered';\n",
    "- SELECT AVG(\"Unit Price (‚Çπ)\") AS average_unit_price FROM orders WHERE Category = 'Furniture';\n",
    "- SELECT * FROM orders WHERE LOWER(\"Material\") = 'glass' AND LOWER(Color) = 'grey';\n",
    "- SELECT COUNT(*) FROM orders WHERE \"Order Date\" >= '2025-05-01';\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\"‚úÖ Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "persist_directory = \"D:\\RAG Task\"\n",
    "collection_name = \"shipment_orders\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 4\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers= [vector_retriever,keyword_retriever],\n",
    "    weights=[0.6,0.4]\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    intent_prompt = f\"\"\"\n",
    "    You are an intent classifier for user questions over an **Orders dataset**.\n",
    "    The table contains the following columns:\n",
    "    Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "    Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "    Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if the query involves structured, measurable, or count-based data.\n",
    "       Examples:\n",
    "       - \"How many orders are pending?\"\n",
    "       - \"What is the total sales amount?\"\n",
    "       - \"Show the average unit price.\"\n",
    "       - \"Count the number of clients.\"\n",
    "       - \"List orders where quantity > 10.\"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if the query involves descriptive or text-based attributes\n",
    "       such true semantic questions, i.e., ones that are descriptive, interpretive, or text-based, not solvable with SQL filters or numbers.\n",
    "T       These rely on understanding meaning, patterns, or unstructured context rather than column values.\n",
    "       Examples:\n",
    "      - Which customers look like regular buyers of furniture?\n",
    "      - Which products are most suitable for modern homes?\n",
    "      - What type of products are popular in Port Mariamouth?\n",
    "      \n",
    "    3. \"hybrid\" ‚Üí if the query mixes both numeric and descriptive components.\n",
    "       Examples:\n",
    "       - What is the total count of clients who bought curtains and Which destination cities frequently receive d√©cor orders?? \n",
    "\n",
    "    4. \"greet\" ‚Üí greetings or conversational openers.\n",
    "       Examples:\n",
    "       - \"Hi\", \"Hello\", \"Good morning\", \"Hey there\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí unrelated or irrelevant to order data.\n",
    "       Examples:\n",
    "       - \"Tell me a joke\", \"What's the time?\", \"Who is the CEO?\"\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Return only one word:\n",
    "    numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\"üß© Validating SQL query: {sql_query}\")\n",
    "\n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚ùå Block unsafe keywords\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = f\"‚ùå Unsafe SQL operation detected: {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚úÖ Ensure valid columns\n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column name used: '{match}'.\"\n",
    "            return state\n",
    "\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\"‚úÖ SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def duckdb_node(state: GraphState):\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "    try:\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # Clean SQL formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"üß† Generated SQL query: {sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        # ‚úÖ Step 1: Validate SQL before execution\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 2: Execute SQL safely\n",
    "        result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # Convert results to text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # ‚úÖ Step 3: Summarize result naturally\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping any rows or adding assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# def duckdb_node(state: GraphState):\n",
    "#     \"\"\"Numeric / structured question handler with natural output\"\"\"\n",
    "#     query = state[\"question\"]\n",
    "#     try:\n",
    "#         sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "#         sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "#         # Clean SQL\n",
    "#         sql_query = (\n",
    "#             sql_query.replace(\"```sql\", \"\")\n",
    "#             .replace(\"```\", \"\")\n",
    "#             .replace(\"`\", \"\")\n",
    "#             .replace(\"SQL:\", \"\")\n",
    "#             .strip()\n",
    "#         )\n",
    "\n",
    "#         print(f\" SQL query: {sql_query}\")\n",
    "\n",
    "#         # Execute SQL on DuckDB\n",
    "#         result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "#         if result_df.empty:\n",
    "#             state[\"answer\"] = \"No matching records found.\"\n",
    "#             return state\n",
    "\n",
    "#         # Convert all rows to text\n",
    "#         result_text = result_df.to_string(index=False)\n",
    "\n",
    "#         # LLM to summarize results naturally\n",
    "#         summary_prompt = f\"\"\"\n",
    "#         The user asked: {query}\n",
    "#         The SQL result is:\n",
    "#         {result_text}\n",
    "\n",
    "#         Write a clear and complete natural language response that lists all relevant names or details.\n",
    "#         Do not skip or summarize results.\n",
    "#         \"\"\"\n",
    "#         answer = llm.invoke(summary_prompt).content.strip()\n",
    "\n",
    "#         state[\"answer\"] = answer\n",
    "\n",
    "#     except Exception as e:\n",
    "#         state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "#     return state\n",
    "def hybrid_node(state: dict):\n",
    "    \"\"\"Handles hybrid queries by splitting into numeric & semantic sub-questions\"\"\"\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "        # Step 1Ô∏è‚É£ Split the query into numeric & semantic\n",
    "        split_prompt = f\"\"\"\n",
    "        Split the user query into numeric and semantic parts.\n",
    "        - Numeric parts: answerable via SQL (count, average, filter, etc.)\n",
    "        - Semantic parts: descriptive, interpretive, or text-based (not solvable by SQL)\n",
    "        - Return clean JSON:\n",
    "        {{\n",
    "            \"numeric\": \"subquestion for numeric logic\",\n",
    "            \"semantic\": \"subquestion for semantic logic\"\n",
    "        }}\n",
    "\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "        import json\n",
    "        try:\n",
    "            split_result = (\n",
    "                split_result.replace(\"```json\", \"\")\n",
    "                            .replace(\"```\", \"\")\n",
    "                            .strip()\n",
    "            )\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "            print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "            print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part = \"\"\n",
    "            semantic_part = \"\"\n",
    "            print(\"‚ö†Ô∏è LLM didn't return valid JSON ‚Äî skipping split.\")\n",
    "\n",
    "        # Step 2Ô∏è‚É£ Numeric logic via DuckDB\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            print(f\"\\nüì§ Sending numeric part to DuckDB: {numeric_part}\")\n",
    "            temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüßÆ NUMERIC RESULT (from SQL):\")\n",
    "            print(numeric_answer or \"No numeric result.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No numeric part detected.\")\n",
    "\n",
    "        # Step 3Ô∏è‚É£ Semantic logic via Retriever\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            print(f\"\\nüì§ Sending semantic part to Retriever: {semantic_part}\")\n",
    "            temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüí¨ SEMANTIC RESULT (from Retriever):\")\n",
    "            print(semantic_answer or \"No semantic result.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No semantic part detected.\")\n",
    "\n",
    "        # Step 4Ô∏è‚É£ Combine both results into final response\n",
    "        print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üßÆ NUMERIC RESULT SUMMARY:\")\n",
    "        print(numeric_answer or \"No numeric result.\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üí¨ SEMANTIC RESULT SUMMARY:\")\n",
    "        print(semantic_answer or \"No semantic result.\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight (from SQL results):\n",
    "        {numeric_answer or \"None\"}\n",
    "\n",
    "        Semantic insight (from retrieved text data):\n",
    "        {semantic_answer or \"None\"}\n",
    "\n",
    "        Now combine these insights into one clear and factual final answer.\n",
    "        Do not mention SQL execution or database details.\n",
    "        Provide a concise, natural explanation.\n",
    "        \"\"\"\n",
    "\n",
    "        combined_response = llm.invoke(combine_prompt)\n",
    "        final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "        # ‚úÖ Print the final combined answer clearly\n",
    "        print(\"\\nüí° FINAL COMBINED ANSWER:\")\n",
    "        print(final_answer if final_answer else \"‚ö†Ô∏è No combined answer generated.\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        # Save only the final answer for the graph output\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "        state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "    # ‚úÖ return after all prints are complete\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        print(f\"You :\",user_input)\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Assistant: Goodbye üëã\")\n",
    "            break\n",
    "\n",
    "        result = app.invoke({\"question\": user_input})\n",
    "        print(f\"Assistant: {result['answer']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
