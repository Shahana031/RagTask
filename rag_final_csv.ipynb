{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c66596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generated 50 labelled chunks for embeddings.\n",
      " Loading existing FAISS index...\n",
      " FAISS index loaded successfully!\n",
      "\n",
      " Smart Query Assistant ready! Type 'exit' to quit.\n",
      "\n",
      "You: Why are certain colors more popular among buyers and how many products in those colors were sold?\n",
      " Detected Intent: hybrid\n",
      "\n",
      "üîÄ [Hybrid Node] Received question ‚Üí Why are certain colors more popular among buyers and how many products in those colors were sold?\n",
      " Raw Split Result: {\n",
      "  \"numeric_parts\": [\n",
      "    \"How many products in those colors were sold\"\n",
      "  ],\n",
      "  \"semantic_parts\": [\n",
      "    \"Why are certain colors more popular among buyers\"\n",
      "  ],\n",
      "  \"dependent\": false\n",
      "}\n",
      "‚úÖ Parsed numeric part(s): ['How many products in those colors were sold']\n",
      "‚úÖ Parsed semantic part(s): ['Why are certain colors more popular among buyers']\n",
      "üîó Dependency flag: False\n",
      "üî¢ Executing 1 numeric subquery(ies)...\n",
      "\n",
      " Numeric Sub-query 1: How many products in those colors were sold\n",
      "\n",
      " Generated SQL query:\n",
      "SELECT SUM(\"Quantity\") AS total_products_sold\n",
      "FROM orders\n",
      "WHERE LOWER(\"Color\") IN ('grey', 'brown');\n",
      " SQLGlot syntax check passed.\n",
      " Validating SQL query: SELECT SUM(\"Quantity\") AS total_products_sold\n",
      "FROM orders\n",
      "WHERE LOWER(\"Color\") IN ('grey', 'brown');\n",
      " SQL validation passed.\n",
      " Executing 1 semantic subquery(ies)...\n",
      "\n",
      " Semantic Sub-query 1: Why are certain colors more popular among buyers\n",
      "\n",
      "‚úÖ Final Combined Answer:\n",
      " **Numeric Result 1:** How many products in those colors were sold\n",
      "The SQL query returned a result indicating that a total of 398 products in the specified colors were sold. This means that when we look at the sales data for the products that match the given color criteria, the cumulative number of units sold amounts to 398. This figure represents the overall sales performance for those particular colors, providing insight into their popularity and demand in the market.\n",
      "\n",
      " **Semantic Result 1:** Why are certain colors more popular among buyers\n",
      "Certain colors are more popular among buyers due to psychological associations, cultural influences, and trends in design. Colors can evoke specific emotions and moods; for example, blue is often seen as calming, while red can be energizing. Additionally, cultural significance and seasonal trends can drive preferences, with certain colors becoming fashionable at different times. Finally, personal taste and the context of the product (e.g., home decor vs. fashion) also play a significant role in color popularity.\n",
      "\n",
      "Assistant:  **Numeric Result 1:** How many products in those colors were sold\n",
      "The SQL query returned a result indicating that a total of 398 products in the specified colors were sold. This means that when we look at the sales data for the products that match the given color criteria, the cumulative number of units sold amounts to 398. This figure represents the overall sales performance for those particular colors, providing insight into their popularity and demand in the market.\n",
      "\n",
      " **Semantic Result 1:** Why are certain colors more popular among buyers\n",
      "Certain colors are more popular among buyers due to psychological associations, cultural influences, and trends in design. Colors can evoke specific emotions and moods; for example, blue is often seen as calming, while red can be energizing. Additionally, cultural significance and seasonal trends can drive preferences, with certain colors becoming fashionable at different times. Finally, personal taste and the context of the product (e.g., home decor vs. fashion) also play a significant role in color popularity.\n",
      "\n",
      "\n",
      "You: hat makes customers choose home decor items and how many orders came from that category?\n",
      " Detected Intent: hybrid\n",
      "\n",
      "üîÄ [Hybrid Node] Received question ‚Üí hat makes customers choose home decor items and how many orders came from that category?\n",
      " Raw Split Result: {\n",
      "  \"numeric_parts\": [\n",
      "    \"how many orders came from the home decor category\"\n",
      "  ],\n",
      "  \"semantic_parts\": [\n",
      "    \"What makes customers choose home decor items\"\n",
      "  ],\n",
      "  \"dependent\": false\n",
      "}\n",
      "‚úÖ Parsed numeric part(s): ['how many orders came from the home decor category']\n",
      "‚úÖ Parsed semantic part(s): ['What makes customers choose home decor items']\n",
      "üîó Dependency flag: False\n",
      "üî¢ Executing 1 numeric subquery(ies)...\n",
      "\n",
      " Numeric Sub-query 1: how many orders came from the home decor category\n",
      "\n",
      " Generated SQL query:\n",
      "SELECT COUNT(*) \n",
      "FROM orders \n",
      "WHERE LOWER(\"Category\") = LOWER('Decor');\n",
      " SQLGlot syntax check passed.\n",
      " Validating SQL query: SELECT COUNT(*) \n",
      "FROM orders \n",
      "WHERE LOWER(\"Category\") = LOWER('Decor');\n",
      " SQL validation passed.\n",
      " Executing 1 semantic subquery(ies)...\n",
      "\n",
      " Semantic Sub-query 1: What makes customers choose home decor items\n",
      "\n",
      "‚úÖ Final Combined Answer:\n",
      " **Numeric Result 1:** how many orders came from the home decor category\n",
      "The SQL query returned a result indicating that there were a total of 11 orders placed in the home decor category. This means that customers made 11 purchases specifically related to home decor items.\n",
      "\n",
      " **Semantic Result 1:** What makes customers choose home decor items\n",
      "Customers choose home decor items for various reasons, including personal style and aesthetic preferences, the desire to create a comfortable and inviting living space, functionality, and the ability to express individuality. Additionally, trends, quality, and the emotional connection to specific items can influence their purchasing decisions.\n",
      "\n",
      "Assistant:  **Numeric Result 1:** how many orders came from the home decor category\n",
      "The SQL query returned a result indicating that there were a total of 11 orders placed in the home decor category. This means that customers made 11 purchases specifically related to home decor items.\n",
      "\n",
      " **Semantic Result 1:** What makes customers choose home decor items\n",
      "Customers choose home decor items for various reasons, including personal style and aesthetic preferences, the desire to create a comfortable and inviting living space, functionality, and the ability to express individuality. Additionally, trends, quality, and the emotional connection to specific items can influence their purchasing decisions.\n",
      "\n",
      "\n",
      "You: exit\n",
      "Assistant: Goodbye !\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List ,  Optional\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sqlglot import parse_one\n",
    "import json\n",
    "\n",
    "#  Step 1: Define paths\n",
    "csv_path = r\"D:\\RAG Task\\Client_Shipment_Orders.csv\"\n",
    "db_path = r\"D:\\RAG Task\\orders.duckdb\"\n",
    "faiss_index_path = r\"D:\\RAG Task\\faiss_index\"\n",
    "\n",
    "#  Step 2: Create or update database table (runs only once)\n",
    "with duckdb.connect(db_path) as con:\n",
    "    # Create the 'orders' table if not already present\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS orders AS\n",
    "        SELECT * FROM read_csv_auto('{csv_path}');\n",
    "    \"\"\")\n",
    "    # Optional: Refresh data if you've updated CSV\n",
    "    # con.execute(f\"DELETE FROM orders; INSERT INTO orders SELECT * FROM read_csv_auto('{csv_path}');\")\n",
    "\n",
    "#  Step 3: Load DataFrame safely for local use\n",
    "with duckdb.connect(db_path) as con:\n",
    "    df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "#  Step 4: Clean / normalize text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.title()\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "----------------------------------\n",
    "TABLE INFORMATION\n",
    "----------------------------------\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "----------------------------------\n",
    "SAMPLE DATA\n",
    "----------------------------------\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for structured or numeric filters.\n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries based on subjective or descriptive logic\n",
    "   such as reasons for cancellation, customer feedback, or preferences.\n",
    "   These are handled separately by a semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names **exactly as shown**.\n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that do not exist.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, comments, or explanations.\n",
    "\n",
    "6. **SAFETY RULES ‚Äî STRICTLY ENFORCED**\n",
    "   - Never modify or delete data.\n",
    "   - Do not use or suggest `UPDATE`, `DELETE`, `INSERT`, `DROP`, `TRUNCATE`, or `ALTER`.\n",
    "   - Do not create or alter schemas, indexes, or tables.\n",
    "   - Only allow read-only operations:  \n",
    "     `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and aggregate functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`).\n",
    "\n",
    "7. **Case Handling:**  \n",
    "   When matching text values (like product or status), use `LOWER()` to make comparisons case-insensitive.  \n",
    "   Example:  \n",
    "   `WHERE LOWER(\"Product Name\") = LOWER('Toilet Bowl')`\n",
    "\n",
    "8. **Special Handling ‚Äî Highest or Maximum Queries:**  \n",
    "   If the user asks questions like  \n",
    "   *\"Who made the highest purchase?\"*,  \n",
    "   *\"Which client has the largest total?\"*, or  \n",
    "   *\"Top buyer / maximum purchase amount\"*,  \n",
    "   use this pattern to avoid grouping errors:\n",
    "   ```sql\n",
    "   SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "   FROM orders\n",
    "   WHERE \"Total Price (‚Çπ)\" = (\n",
    "       SELECT MAX(\"Total Price (‚Çπ)\") FROM orders\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\" Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "#  Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "#  Create or load FAISS vector store\n",
    "if os.path.exists(faiss_index_path):\n",
    "    print(\" Loading existing FAISS index...\")\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(\n",
    "            faiss_index_path, \n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\" FAISS index loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error loading FAISS index: {e}\")\n",
    "        print(\" Creating new FAISS index...\")\n",
    "        vector_store = FAISS.from_documents(documents, embeddings)\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "        print(\" New FAISS index created and saved!\")\n",
    "else:\n",
    "    print(\" Creating new FAISS index...\")\n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(faiss_index_path, exist_ok=True)\n",
    "    vector_store.save_local(faiss_index_path)\n",
    "    print(\" FAISS index created and saved!\")\n",
    "\n",
    "#  Set up retrievers\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 15})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 15\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, keyword_retriever],\n",
    "    weights=[0.6, 0.4]\n",
    ")\n",
    " \n",
    "class GraphStateRequired(TypedDict):\n",
    "    question: str  # Always required\n",
    "    \n",
    "class GraphState(GraphStateRequired, total=False):\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "    sql_query: str\n",
    "    validation_error: Optional[str]\n",
    "\n",
    "\n",
    "def intent_node(state: GraphState,config = None) -> GraphState:\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    intent_prompt = f\"\"\"\n",
    "        You are an intent classifier for user questions over an **Orders dataset**.\n",
    "        The table has the following columns:\n",
    "        Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "        Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "        Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "        RULE (important): If the user asks about *popularity, trends, likelihood, aesthetics, emotional value, suitability, or \"best suited\"*, treat the question as **semantic** ‚Äî even if the question mentions column names like Category or Product. Those words request interpretation, not a raw SQL lookup.\n",
    "\n",
    "        Your task is to classify the user's question into one of the following intents:\n",
    "\n",
    "        ---\n",
    "\n",
    "        1. **numeric** ‚Üí The question can be answered using structured, factual, or count-based data directly from the dataset.\n",
    "        Includes lookups, filters, conditions, or measurable aggregations.\n",
    "\n",
    "         Examples:\n",
    "        - \"How many orders are pending?\"\n",
    "        - \"List all clients whose orders are cancelled.\"\n",
    "        - \"Show orders where quantity > 10.\"\n",
    "        - \"Who bought d√©cor items?\"\n",
    "        - \"List clients who ordered furniture and curtains.\"\n",
    "        - \"Show total sales amount from Bangalore.\"\n",
    "        - \"Names of clients who placed multiple orders.\"\n",
    "        - \"List all clients whose orders are cancelled and who prefer d√©cor items.\"\n",
    "        - \"What is the origin of Kara Mata?\"    <-- entity attribute lookup ‚Üí numeric\n",
    "\n",
    "         NOTE: Entity attribute lookups (e.g., \"what is the product Jesse Williams ordered?\") count as **numeric**.\n",
    "\n",
    "        ---\n",
    "\n",
    "        2. **semantic** ‚Üí The question requires interpretation, reasoning, or subjective understanding\n",
    "        that cannot be directly derived from the dataset‚Äôs structured fields.\n",
    "        These questions involve opinions, trends, likelihood, aesthetics or suitability.\n",
    "\n",
    "         Examples:\n",
    "        - \"Which customers are likely to be loyal customers?\"\n",
    "        - \"Which products seem to be trending this month?\"\n",
    "        - \"Which items are best suited for festive seasons?\"\n",
    "        - \"Which products have emotional or aesthetic value?\"\n",
    "        - \"What categories are most popular among new customers?\"\n",
    "        - \"Which products are considered budget-friendly?\"\n",
    "        - \"Which customers might recommend our products?\"\n",
    "        - \"Which destinations appear to be popular among high-value clients?\"\n",
    "\n",
    "        KEY: If the phrasing contains words like *popular, trending, likely, seem, appear, best suited, emotional, aesthetic, preference, suitability* ‚Äî treat as **semantic**.\n",
    "\n",
    "        ---\n",
    "\n",
    "        3. **hybrid** ‚Üí The question contains both numeric and semantic parts.\n",
    "\n",
    "         Examples:\n",
    "        - \"What is the total sales amount, and which products are most popular in premium homes?\"\n",
    "        - \"Count d√©cor orders and explain which clients usually place them.\"\n",
    "\n",
    "        ---\n",
    "\n",
    "        4. **greet** ‚Üí Simple greetings (Hi, Hello, etc.)\n",
    "\n",
    "        ---\n",
    "\n",
    "        5. **ignore** ‚Üí Questions unrelated to the dataset.\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Return only one word: numeric, semantic, hybrid, greet, or ignore.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\" Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: GraphState,config = None)-> GraphState:\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: GraphState , config = None) -> GraphState:\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: GraphState,config = None)-> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\" Validating SQL query: {sql_query}\")\n",
    "\n",
    "    # 1. Ensure it's a SELECT query\n",
    "    if not sql_query.lower().lstrip().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \" Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # 2. Block dangerous operations\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = (\n",
    "            f\" Unsafe SQL operation detected. \"\n",
    "            f\"Keywords like {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # 3. Validate quoted column names used as actual columns (ignore aliases produced by AS)\n",
    "    quoted_names = re.findall(r'\"(.*?)\"', sql_query)\n",
    "    for name in quoted_names:\n",
    "        # if name exactly matches a real column, OK\n",
    "        if name in VALID_COLUMNS:\n",
    "            continue\n",
    "\n",
    "        # if the quoted name is used as an alias (AS \"name\"), skip validation\n",
    "        alias_pattern = re.search(r'\\bAS\\s+\"?' + re.escape(name) + r'\"?', sql_query, flags=re.IGNORECASE)\n",
    "        if alias_pattern:\n",
    "            # it's an alias; safe to ignore\n",
    "            continue\n",
    "\n",
    "        # otherwise it's an invalid column name\n",
    "        state[\"validation_error\"] = f\" Invalid column name used: '{name}'.\"\n",
    "        return state\n",
    "\n",
    "    # Passed all checks\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\" SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def duckdb_node(state: GraphState,config = None)-> GraphState:\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL with SQLGlot before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        #  Step 1: Ask LLM to generate SQL\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        #  Step 2: Clean LLM formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"\\n Generated SQL query:\\n{sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        #  Step 3: Syntax validation using SQLGlot\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "            print(\" SQLGlot syntax check passed.\")\n",
    "        except Exception as parse_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error detected: {parse_err}\"\n",
    "            return state\n",
    "\n",
    "        #  Step 4: Custom SQL safety validation\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        #  Step 5: Safe execution inside a local DuckDB context\n",
    "        try:\n",
    "            with duckdb.connect(db_path) as con:\n",
    "                result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "        except Exception as exec_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL execution failed: {exec_err}\"\n",
    "            return state\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        #  Step 6: Convert results to plain text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        #  Step 7: Generate human-readable summary\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping rows or making assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def hybrid_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    Handles hybrid, multi-intent queries that may contain:\n",
    "      - multiple numeric sub-queries (SQL-based)\n",
    "      - multiple semantic sub-queries (LLM-based)\n",
    "      - or a mix of both.\n",
    "    Ensures separate execution and clear structured output.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "    # 1Ô∏è‚É£ SPLITTING PHASE ‚Äî Identify all numeric & semantic sub-questions\n",
    "    \n",
    "    split_prompt = f\"\"\"\n",
    "    You are a professional query decomposition assistant.\n",
    "    Split the following user question into atomic sub-questions.\n",
    "\n",
    "    Each sub-question should be labeled as:\n",
    "      - numeric ‚Üí if it can be answered using SQL filters, counts, or aggregates (explicit SQL lookups or attribute lookups e.g., \"what is the product Jesse Williams ordered?\")\n",
    "      - semantic ‚Üí if it requires descriptive, interpretive, or trend-based reasoning (popularity, trending, suitability, emotional/aesthetic value).\n",
    "\n",
    "    Important rule: If a sub-question contains words like\n",
    "    [\"popular\", \"trending\", \"likely\", \"seem\", \"appear\", \"best suited\", \"emotional\", \"aesthetic\", \"budget-friendly\", \"suitable for\", \"preference\", \"preference for\", \"trend\"],\n",
    "    classify that sub-question as **semantic** (these require interpretation), even if they mention columns like Category or Product.\n",
    "\n",
    "    Return JSON strictly in this format:\n",
    "    {{\n",
    "      \"numeric_parts\": [ \"...\" ],\n",
    "      \"semantic_parts\": [ \"...\" ],\n",
    "      \"dependent\": true/false\n",
    "    }}\n",
    "\n",
    "    Examples:\n",
    "    1. \"List all clients whose orders are cancelled and list the clients who prefer decor items\"\n",
    "    ‚Üí {{\n",
    "      \"numeric_parts\": [\n",
    "        \"List all clients whose orders are cancelled\",\n",
    "        \"List all clients who prefer decor items\"\n",
    "      ],\n",
    "      \"semantic_parts\": [],\n",
    "      \"dependent\": false\n",
    "    }}\n",
    "\n",
    "    2. \"What categories are most popular among new customers and Which products have emotional or aesthetic value?\"\n",
    "    ‚Üí {{\n",
    "      \"numeric_parts\": [],\n",
    "      \"semantic_parts\": [\n",
    "        \"What categories are most popular among new customers\",\n",
    "        \"Which products have emotional or aesthetic value\"\n",
    "      ],\n",
    "      \"dependent\": false\n",
    "    }}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        split_result = llm.invoke(split_prompt).content\n",
    "        split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        print(f\" Raw Split Result: {split_result}\")\n",
    "        split_data = json.loads(split_result)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error parsing split result: {e}\")\n",
    "        split_data = {\"numeric_parts\": [], \"semantic_parts\": [], \"dependent\": False}\n",
    "\n",
    "    numeric_parts = split_data.get(\"numeric_parts\", [])\n",
    "    semantic_parts = split_data.get(\"semantic_parts\", [])\n",
    "    dependent = split_data.get(\"dependent\", False)\n",
    "\n",
    "    print(f\"‚úÖ Parsed numeric part(s): {numeric_parts}\")\n",
    "    print(f\"‚úÖ Parsed semantic part(s): {semantic_parts}\")\n",
    "    print(f\"üîó Dependency flag: {dependent}\")\n",
    "\n",
    "    # 2Ô∏è‚É£ EXECUTE NUMERIC SUB-QUERIES\n",
    "    numeric_results = []\n",
    "    if numeric_parts:\n",
    "        print(f\"üî¢ Executing {len(numeric_parts)} numeric subquery(ies)...\")\n",
    "        for i, sub_q in enumerate(numeric_parts, 1):\n",
    "            print(f\"\\n Numeric Sub-query {i}: {sub_q}\")\n",
    "            temp_state = {\"question\": sub_q, \"intent\": \"numeric\", \"context\": [], \"answer\": \"\"}\n",
    "            try:\n",
    "                numeric_state = duckdb_node(temp_state)\n",
    "                result = numeric_state.get(\"answer\", \"\")\n",
    "                numeric_results.append({\n",
    "                    \"subquery\": sub_q,\n",
    "                    \"result\": result\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\" Error in numeric sub-query {i}: {e}\")\n",
    "\n",
    "    # 3Ô∏è‚É£ EXECUTE SEMANTIC SUB-QUERIES\n",
    "    semantic_results = []\n",
    "    if semantic_parts:\n",
    "        print(f\" Executing {len(semantic_parts)} semantic subquery(ies)...\")\n",
    "        for i, sub_q in enumerate(semantic_parts, 1):\n",
    "            print(f\"\\n Semantic Sub-query {i}: {sub_q}\")\n",
    "            temp_state = {\"question\": sub_q, \"intent\": \"semantic\", \"context\": [], \"answer\": \"\"}\n",
    "            try:\n",
    "                semantic_state = retriever_node(temp_state)\n",
    "                result = semantic_state.get(\"answer\", \"\")\n",
    "                semantic_results.append({\n",
    "                    \"subquery\": sub_q,\n",
    "                    \"result\": result\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\" Error in semantic sub-query {i}: {e}\")\n",
    "\n",
    "    # 4Ô∏è‚É£ FORMAT & MERGE RESULTS CLEARLY\n",
    "    combined_output = []\n",
    "\n",
    "    if numeric_results:\n",
    "        for i, entry in enumerate(numeric_results, 1):\n",
    "            combined_output.append(\n",
    "                f\" **Numeric Result {i}:** {entry['subquery']}\\n{entry['result']}\\n\"\n",
    "            )\n",
    "\n",
    "    if semantic_results:\n",
    "        for i, entry in enumerate(semantic_results, 1):\n",
    "            combined_output.append(\n",
    "                f\" **Semantic Result {i}:** {entry['subquery']}\\n{entry['result']}\\n\"\n",
    "            )\n",
    "\n",
    "    if not combined_output:\n",
    "        combined_output = [\"‚ö†Ô∏è No valid results found for this query.\"]\n",
    "\n",
    "    final_answer = \"\\n\".join(combined_output)\n",
    "    print(f\"\\n‚úÖ Final Combined Answer:\\n{final_answer}\")\n",
    "\n",
    "    # Store cleanly into state\n",
    "    state[\"answer\"] = final_answer\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            print(f\"You: {user_input}\")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Assistant: Goodbye !\")\n",
    "                break\n",
    "\n",
    "            result = app.invoke({\"question\": user_input})\n",
    "            print(f\"Assistant: {result['answer']}\\n\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistant: Goodbye ! \")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\" Error: {str(e)}\")\n",
    "            print(\"Please try again with a different question.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
