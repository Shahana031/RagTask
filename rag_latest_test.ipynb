{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever,EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# df = duckdb.read_csv(csv_path).df()\n",
    "\n",
    "csv_path = \"Client_Shipment_Orders.csv\"\n",
    "\n",
    "# Load CSV safely\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize text columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype(str).str.title().str.strip()\n",
    "\n",
    "# Reconnect DuckDB safely\n",
    "con = duckdb.connect()\n",
    "con.execute(\"CREATE OR REPLACE TABLE orders AS SELECT * FROM df\")\n",
    "\n",
    "# Use a safe path for Chroma\n",
    "persist_directory = r\"D:\\RAG_Task\"  \n",
    "\n",
    "\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "----------------------------------\n",
    "TABLE INFORMATION\n",
    "----------------------------------\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "----------------------------------\n",
    "SAMPLE DATA\n",
    "----------------------------------\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for structured or numeric filters.\n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries based on subjective or descriptive logic\n",
    "   such as reasons for cancellation, customer feedback, or preferences.\n",
    "   These are handled separately by a semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names **exactly as shown**.\n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that do not exist.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, comments, or explanations.\n",
    "\n",
    "6. **SAFETY RULES ‚Äî STRICTLY ENFORCED**\n",
    "   - Never modify or delete data.\n",
    "   - Do not use or suggest `UPDATE`, `DELETE`, `INSERT`, `DROP`, `TRUNCATE`, or `ALTER`.\n",
    "   - Do not create or alter schemas, indexes, or tables.\n",
    "   - Only allow read-only operations:  \n",
    "     `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and aggregate functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`).\n",
    "\n",
    "7. **Case Handling:**  \n",
    "   When matching text values (like product or status), use `LOWER()` to make comparisons case-insensitive.  \n",
    "   Example:  \n",
    "   `WHERE LOWER(\"Product Name\") = LOWER('Toilet Bowl')`\n",
    "\n",
    "8. **Special Handling ‚Äî Highest or Maximum Queries:**  \n",
    "   If the user asks questions like  \n",
    "   *‚ÄúWho made the highest purchase?‚Äù*,  \n",
    "   *‚ÄúWhich client has the largest total?‚Äù*, or  \n",
    "   *‚ÄúTop buyer / maximum purchase amount‚Äù*,  \n",
    "   use this pattern to avoid grouping errors:\n",
    "   ```sql\n",
    "   SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "   FROM orders\n",
    "   WHERE \"Total Price (‚Çπ)\" = (\n",
    "       SELECT MAX(\"Total Price (‚Çπ)\") FROM orders\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\"‚úÖ Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "persist_directory = \"D:\\RAG Task\"\n",
    "collection_name = \"shipment_orders\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers= [vector_retriever,keyword_retriever],\n",
    "    weights=[0.6,0.4]\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    intent_prompt = f\"\"\"\n",
    "    You are an intent classifier for user questions over an **Orders dataset**.\n",
    "    The table contains the following columns:\n",
    "    Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "    Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "    Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if the query involves structured, measurable, or count-based data.\n",
    "       Examples:\n",
    "       - \"How many orders are pending?\"\n",
    "       - \"What is the total sales amount?\"\n",
    "       - \"Show the average unit price.\"\n",
    "       - \"Count the number of clients.\"\n",
    "       - \"List orders where quantity > 10.\n",
    "       - \"Who made the highest purchase?\"\n",
    "       - \"names of customers who ordered bed \"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if the query involves descriptive or text-based attributes\n",
    "       such true semantic questions, i.e., ones that are descriptive, interpretive, or text-based, not solvable with SQL filters or numbers.\n",
    "T       These rely on understanding meaning, patterns, or unstructured context rather than column values.\n",
    "       Examples:\n",
    "      - Which customers look like regular buyers of furniture?\n",
    "      - Which products are most suitable for modern homes?\n",
    "      - What type of products are popular in Port Mariamouth?\n",
    "      \n",
    "    3. \"hybrid\" ‚Üí if the query mixes both numeric and descriptive components.\n",
    "       Examples:\n",
    "       - What is the total count of clients who bought curtains and Which destination cities frequently receive d√©cor orders?? \n",
    "\n",
    "    4. \"greet\" ‚Üí greetings or conversational openers.\n",
    "       Examples:\n",
    "       - \"Hi\", \"Hello\", \"Good morning\", \"Hey there\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí unrelated or irrelevant to order data.\n",
    "       Examples:\n",
    "       - \"Tell me a joke\", \"What's the time?\", \"Who is the CEO?\"\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Return only one word:\n",
    "    numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "from sqlglot import parse_one\n",
    "import re\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\"üß© Validating SQL query: {sql_query}\")\n",
    "\n",
    "    # ‚úÖ 1. Ensure it's a SELECT query\n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚ùå 2. Block dangerous operations\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = (\n",
    "            f\"‚ùå Unsafe SQL operation detected. \"\n",
    "            f\"Keywords like {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # ‚úÖ 3. Validate columns used in SQL (prevent hallucinated fields)\n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column name used: '{match}'.\"\n",
    "            return state\n",
    "\n",
    "    # ‚úÖ 4. Passed all checks\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\"‚úÖ SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "def duckdb_node(state: dict):\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL with SQLGlot before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        # üß† Step 1: Ask LLM to generate SQL\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # üßπ Step 2: Clean LLM formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüß† Generated SQL query:\\n{sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        # ‚úÖ Step 3: Syntax validation using SQLGlot\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "            print(\"‚úÖ SQLGlot syntax check passed.\")\n",
    "        except Exception as parse_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error detected: {parse_err}\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 4: Custom SQL safety validation\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 5: Safe execution inside a local DuckDB context\n",
    "        try:\n",
    "            with duckdb.connect() as temp_con:\n",
    "                temp_con.register(\"orders\", df)\n",
    "                result_df = temp_con.execute(sql_query).fetchdf()\n",
    "        except Exception as exec_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL execution failed: {exec_err}\"\n",
    "            return state\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 6: Convert results to plain text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # ‚úÖ Step 7: Generate human-readable summary\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping rows or making assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def hybrid_node(state: dict):\n",
    "    \"\"\"Handles hybrid queries (numeric + semantic), distinguishes dependent vs independent sub-questions.\"\"\"\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "        # 1Ô∏è‚É£ Strict split prompt with dependency detection\n",
    "        split_prompt = f\"\"\"\n",
    "            You are a **strict query-splitting assistant** for a hybrid SQL-semantic reasoning system.\n",
    "\n",
    "            Your task is to analyze a user's natural question and split it into two precise sub-questions:\n",
    "            - \"numeric\": a part that involves quantitative or SQL-based reasoning (e.g., count, sum, max, min, average, total, etc.)\n",
    "            - \"semantic\": a descriptive or entity-based part that involves understanding names, descriptions, or meanings.\n",
    "            Also, specify whether these two parts are **dependent** (the semantic part relies on the numeric answer)\n",
    "            or **independent** (they can be answered separately).\n",
    "\n",
    "            Be extremely careful:\n",
    "            - DO NOT merge both questions into one.\n",
    "            - DO NOT make assumptions or hallucinate missing data.\n",
    "            - Your output MUST always be a valid JSON object with exactly three keys: \"numeric\", \"semantic\", and \"dependent\".\n",
    "            - Always detect if the question indirectly involves SQL-style numeric reasoning even if phrased differently (e.g., ‚Äúbiggest‚Äù, ‚Äúmost‚Äù, ‚Äúhighest‚Äù, ‚Äútop‚Äù, etc.).\n",
    "\n",
    "            ---\n",
    "            ### ‚öôÔ∏è SQL Integration Note\n",
    "            If the question is **dependent** (e.g., \"Who made the highest purchase and how much was it?\"),\n",
    "            this will later be used by a SQL generator. So:\n",
    "            - Ensure the \"numeric\" question extracts the quantitative aspect (like ‚Äúhighest purchase amount‚Äù).\n",
    "            - Ensure the \"semantic\" question clearly describes the related entity (like ‚Äúwho made that purchase‚Äù).\n",
    "            - The SQL generator will then produce a **single combined SQL query** that includes both numeric and descriptive fields \n",
    "            (e.g., client name + total price) to answer both parts together.\n",
    "\n",
    "            ---\n",
    "            ### ‚úÖ Examples\n",
    "\n",
    "            **Example 1 ‚Äî Dependent query**\n",
    "            User question: \"Who made the highest purchase and how much was the amount?\"\n",
    "            Output:\n",
    "            {{\n",
    "            \"numeric\": \"What is the highest purchase amount?\",\n",
    "            \"semantic\": \"Who made that highest purchase?\",\n",
    "            \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 2 ‚Äî Dependent query**\n",
    "            User question: \"Which product had the highest sales and what was the total revenue for it?\"\n",
    "            Output:\n",
    "            {{\n",
    "            \"numeric\": \"Which product had the highest sales?\",\n",
    "            \"semantic\": \"What was the total revenue for that product?\",\n",
    "            \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 3 ‚Äî Independent query**\n",
    "            User question: \"How many orders were placed, and who are the top 5 customers?\"\n",
    "            Output:\n",
    "            {{\n",
    "            \"numeric\": \"How many orders were placed?\",\n",
    "            \"semantic\": \"Who are the top 5 customers?\",\n",
    "            \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            **Example 4 ‚Äî Independent query**\n",
    "            User question: \"What is the total revenue and list all product categories?\"\n",
    "            Output:\n",
    "            {{\n",
    "            \"numeric\": \"What is the total revenue?\",\n",
    "            \"semantic\": \"List all product categories.\",\n",
    "            \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            ---\n",
    "            Now process this question and return **valid JSON only** (no explanations):\n",
    "\n",
    "            Question: {question}\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "        import json\n",
    "        try:\n",
    "            split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "            dependent = parsed.get(\"dependent\", False)\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part, semantic_part, dependent = \"\", \"\", False\n",
    "            print(\"‚ö†Ô∏è Invalid JSON in split, skipping.\")\n",
    "\n",
    "        print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "        print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "        print(f\"üîó Dependency detected: {dependent}\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Get numeric answer from DuckDB\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüßÆ NUMERIC RESULT (from SQL):\")\n",
    "            print(numeric_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No numeric part found.\")\n",
    "\n",
    "        # 3Ô∏è‚É£ Get semantic answer from Retriever\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüí¨ SEMANTIC RESULT (from Retriever):\")\n",
    "            print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No semantic part found.\")\n",
    "\n",
    "        # 4Ô∏è‚É£ Validation: only if dependent\n",
    "        if dependent and numeric_answer and semantic_answer:\n",
    "            validation_prompt = f\"\"\"\n",
    "            The following query is DEPENDENT ‚Äî the semantic part relies on the numeric SQL result.\n",
    "            Check if the semantic result aligns factually with the numeric SQL result.\n",
    "            Focus on consistency between numbers, names, or facts.\n",
    "\n",
    "            Numeric result:\n",
    "            {numeric_answer}\n",
    "\n",
    "            Semantic result:\n",
    "            {semantic_answer}\n",
    "\n",
    "            Reply with JSON:\n",
    "            {{\n",
    "                \"is_consistent\": true/false,\n",
    "                \"issues\": \"describe discrepancies briefly\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            validation = llm.invoke(validation_prompt).content.strip()\n",
    "            print(\"\\nüîç Validation result:\", validation)\n",
    "\n",
    "            try:\n",
    "                validation_json = json.loads(validation.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "                consistent = validation_json.get(\"is_consistent\", True)\n",
    "            except:\n",
    "                consistent = True  # fallback\n",
    "\n",
    "            # Retry if inconsistent\n",
    "            if not consistent:\n",
    "                print(\"‚ö†Ô∏è Semantic answer inconsistent with SQL ‚Äî retrying with numeric context...\")\n",
    "                retry_prompt = f\"\"\"\n",
    "                The user asked: {question}\n",
    "\n",
    "                The numeric SQL result says:\n",
    "                {numeric_answer}\n",
    "\n",
    "                The previous semantic answer was:\n",
    "                {semantic_answer}\n",
    "\n",
    "                Please re-generate a consistent, unified answer that aligns with the numeric facts.\n",
    "                \"\"\"\n",
    "                semantic_answer = llm.invoke(retry_prompt).content.strip()\n",
    "                print(\"\\n‚ôªÔ∏è RETRIED SEMANTIC ANSWER:\")\n",
    "                print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚úÖ Independent or single-part query ‚Äî skipping validation.\")\n",
    "\n",
    "        # 5Ô∏è‚É£ Combine answers\n",
    "        print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight (SQL result):\n",
    "        {numeric_answer or \"None\"}\n",
    "\n",
    "        Semantic insight (retrieved/explained result):\n",
    "        {semantic_answer or \"None\"}\n",
    "\n",
    "        Combine both into one clear, factual, and natural-language answer.\n",
    "        Avoid SQL or technical terms.\n",
    "        \"\"\"\n",
    "        combined_response = llm.invoke(combine_prompt)\n",
    "        final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "        # Assign final answer\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "        state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "# def hybrid_node(state: dict):\n",
    "#     \"\"\"Handles hybrid queries by splitting into numeric & semantic sub-questions with validation & retry.\"\"\"\n",
    "#     try:\n",
    "#         question = state[\"question\"]\n",
    "#         print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "#         # 1Ô∏è‚É£ Split query into numeric & semantic parts\n",
    "#         split_prompt = f\"\"\"\n",
    "#         Split the user query into numeric and semantic parts.\n",
    "#         - Numeric: can be answered by SQL (count, filter, sum, max, etc.)\n",
    "#         - Semantic: descriptive or entity-based part\n",
    "#         Return valid JSON only:\n",
    "#         {{\n",
    "#             \"numeric\": \"numeric sub-question\",\n",
    "#             \"semantic\": \"semantic sub-question\"\n",
    "#         }}\n",
    "#         Question: {question}\n",
    "#         \"\"\"\n",
    "#         split_result = llm.invoke(split_prompt).content.strip()\n",
    "#         print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "#         import json\n",
    "#         try:\n",
    "#             split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "#             parsed = json.loads(split_result)\n",
    "#             numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "#             semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "#         except json.JSONDecodeError:\n",
    "#             numeric_part, semantic_part = \"\", \"\"\n",
    "#             print(\"‚ö†Ô∏è Invalid JSON in split, skipping.\")\n",
    "#         print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "#         print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "\n",
    "#         # 2Ô∏è‚É£ Get numeric answer from DuckDB\n",
    "#         numeric_answer = \"\"\n",
    "#         if numeric_part:\n",
    "#             temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "#             numeric_state = duckdb_node(temp_state)\n",
    "#             numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "#             print(\"\\nüßÆ NUMERIC RESULT (from SQL):\")\n",
    "#             print(numeric_answer)\n",
    "#         else:\n",
    "#             print(\"‚ö†Ô∏è No numeric part found.\")\n",
    "\n",
    "#         # 3Ô∏è‚É£ Get semantic answer from Retriever\n",
    "#         semantic_answer = \"\"\n",
    "#         if semantic_part:\n",
    "#             temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "#             semantic_state = retriever_node(temp_state)\n",
    "#             semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "#             print(\"\\nüí¨ SEMANTIC RESULT (from Retriever):\")\n",
    "#             print(semantic_answer)\n",
    "#         else:\n",
    "#             print(\"‚ö†Ô∏è No semantic part found.\")\n",
    "\n",
    "#         # 4Ô∏è‚É£ Validation: check for missing or inconsistent entities\n",
    "#         if numeric_answer and semantic_answer:\n",
    "#             validation_prompt = f\"\"\"\n",
    "#             Check if the following semantic answer is factually consistent with the numeric SQL result.\n",
    "#             Highlight missing or inconsistent details, especially names, numbers, or facts.\n",
    "\n",
    "#             Numeric result:\n",
    "#             {numeric_answer}\n",
    "\n",
    "#             Semantic result:\n",
    "#             {semantic_answer}\n",
    "\n",
    "#             Reply with:\n",
    "#             {{\n",
    "#                 \"is_consistent\": true/false,\n",
    "#                 \"issues\": \"describe discrepancies briefly\"\n",
    "#             }}\n",
    "#             \"\"\"\n",
    "#             validation = llm.invoke(validation_prompt).content.strip()\n",
    "#             print(\"\\nüîç Validation result:\", validation)\n",
    "\n",
    "#             try:\n",
    "#                 validation_json = json.loads(validation.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "#                 consistent = validation_json.get(\"is_consistent\", True)\n",
    "#             except:\n",
    "#                 consistent = True  # fail-safe\n",
    "\n",
    "#             # 5Ô∏è‚É£ If inconsistent ‚Äî retry semantic reasoning with context\n",
    "#             if not consistent:\n",
    "#                 print(\"‚ö†Ô∏è Semantic answer inconsistent with SQL ‚Äî retrying with numeric context...\")\n",
    "#                 retry_prompt = f\"\"\"\n",
    "#                 The user asked: {question}\n",
    "\n",
    "#                 The numeric SQL result says:\n",
    "#                 {numeric_answer}\n",
    "\n",
    "#                 The previous semantic answer was:\n",
    "#                 {semantic_answer}\n",
    "\n",
    "#                 Please re-generate a consistent, unified answer that aligns with the numeric facts.\n",
    "#                 \"\"\"\n",
    "#                 semantic_answer = llm.invoke(retry_prompt).content.strip()\n",
    "#                 print(\"\\n‚ôªÔ∏è RETRIED SEMANTIC ANSWER:\")\n",
    "#                 print(semantic_answer)\n",
    "\n",
    "#         # 6Ô∏è‚É£ Final combination\n",
    "#         print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "#         combine_prompt = f\"\"\"\n",
    "#         The user originally asked: {question}\n",
    "\n",
    "#         Numeric insight (SQL result):\n",
    "#         {numeric_answer or \"None\"}\n",
    "\n",
    "#         Semantic insight (retrieved/explained result):\n",
    "#         {semantic_answer or \"None\"}\n",
    "\n",
    "#         Combine both into one clear, factual, and natural-language answer.\n",
    "#         Avoid SQL or technical references.\n",
    "#         \"\"\"\n",
    "#         combined_response = llm.invoke(combine_prompt)\n",
    "#         final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "#         # print(\"\\nüí° FINAL COMBINED ANSWER:\")\n",
    "#         # print(final_answer)\n",
    "#         state[\"answer\"] = final_answer\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "#         state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "#     return state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        print(f\"You :\",user_input)\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Assistant: Goodbye üëã\")\n",
    "            break\n",
    "\n",
    "        result = app.invoke({\"question\": user_input})\n",
    "        print(f\"Assistant: {result['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846439bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever,EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Step 1: Define paths\n",
    "csv_path = r\"D:\\RAG Task\\Client_Shipment_Orders.csv\"\n",
    "db_path = r\"D:\\RAG Task\\orders.duckdb\"\n",
    "\n",
    "# ‚úÖ Step 2: Create or update database table (runs only once)\n",
    "with duckdb.connect(db_path) as con:\n",
    "    # Create the 'orders' table if not already present\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS orders AS\n",
    "        SELECT * FROM read_csv_auto('{csv_path}');\n",
    "    \"\"\")\n",
    "    # Optional: Refresh data if you‚Äôve updated CSV\n",
    "    # con.execute(f\"DELETE FROM orders; INSERT INTO orders SELECT * FROM read_csv_auto('{csv_path}');\")\n",
    "\n",
    "# ‚úÖ Step 3: Load DataFrame safely for local use\n",
    "with duckdb.connect(db_path) as con:\n",
    "    df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "# ‚úÖ Step 4: Clean / normalize text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# ‚úÖ Step 5: Define persistent directory for embeddings / Chroma\n",
    "persist_directory = r\"D:\\RAG Task\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "----------------------------------\n",
    "TABLE INFORMATION\n",
    "----------------------------------\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "----------------------------------\n",
    "SAMPLE DATA\n",
    "----------------------------------\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for structured or numeric filters.\n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries based on subjective or descriptive logic\n",
    "   such as reasons for cancellation, customer feedback, or preferences.\n",
    "   These are handled separately by a semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names **exactly as shown**.\n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that do not exist.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, comments, or explanations.\n",
    "\n",
    "6. **SAFETY RULES ‚Äî STRICTLY ENFORCED**\n",
    "   - Never modify or delete data.\n",
    "   - Do not use or suggest `UPDATE`, `DELETE`, `INSERT`, `DROP`, `TRUNCATE`, or `ALTER`.\n",
    "   - Do not create or alter schemas, indexes, or tables.\n",
    "   - Only allow read-only operations:  \n",
    "     `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and aggregate functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`).\n",
    "\n",
    "7. **Case Handling:**  \n",
    "   When matching text values (like product or status), use `LOWER()` to make comparisons case-insensitive.  \n",
    "   Example:  \n",
    "   `WHERE LOWER(\"Product Name\") = LOWER('Toilet Bowl')`\n",
    "\n",
    "8. **Special Handling ‚Äî Highest or Maximum Queries:**  \n",
    "   If the user asks questions like  \n",
    "   *‚ÄúWho made the highest purchase?‚Äù*,  \n",
    "   *‚ÄúWhich client has the largest total?‚Äù*, or  \n",
    "   *‚ÄúTop buyer / maximum purchase amount‚Äù*,  \n",
    "   use this pattern to avoid grouping errors:\n",
    "   ```sql\n",
    "   SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "   FROM orders\n",
    "   WHERE \"Total Price (‚Çπ)\" = (\n",
    "       SELECT MAX(\"Total Price (‚Çπ)\") FROM orders\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\"‚úÖ Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "persist_directory = \"D:\\RAG Task\"\n",
    "collection_name = \"shipment_orders\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers= [vector_retriever,keyword_retriever],\n",
    "    weights=[0.6,0.4]\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    intent_prompt = f\"\"\"\n",
    "    You are an intent classifier for user questions over an **Orders dataset**.\n",
    "    The table contains the following columns:\n",
    "    Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "    Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "    Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if the query involves structured, measurable, or count-based data.\n",
    "       Examples:\n",
    "       - \"How many orders are pending?\"\n",
    "       - \"What is the total sales amount?\"\n",
    "       - \"Show the average unit price.\"\n",
    "       - \"Count the number of clients.\"\n",
    "       - \"List orders where quantity > 10.\n",
    "       - \"Who made the highest purchase?\"\n",
    "       - \"names of customers who ordered bed \"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if the query involves descriptive or text-based attributes\n",
    "       such true semantic questions, i.e., ones that are descriptive, interpretive, or text-based, not solvable with SQL filters or numbers.\n",
    "T       These rely on understanding meaning, patterns, or unstructured context rather than column values.\n",
    "       Examples:\n",
    "      - Which customers look like regular buyers of furniture?\n",
    "      - Which products are most suitable for modern homes?\n",
    "      - What type of products are popular in Port Mariamouth?\n",
    "      \n",
    "    3. \"hybrid\" ‚Üí if the query mixes both numeric and descriptive components.\n",
    "       Examples:\n",
    "       - What is the total count of clients who bought curtains and Which destination cities frequently receive d√©cor orders?? \n",
    "\n",
    "    4. \"greet\" ‚Üí greetings or conversational openers.\n",
    "       Examples:\n",
    "       - \"Hi\", \"Hello\", \"Good morning\", \"Hey there\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí unrelated or irrelevant to order data.\n",
    "       Examples:\n",
    "       - \"Tell me a joke\", \"What's the time?\", \"Who is the CEO?\"\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Return only one word:\n",
    "    numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "from sqlglot import parse_one\n",
    "import re\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\"üß© Validating SQL query: {sql_query}\")\n",
    "\n",
    "    # ‚úÖ 1. Ensure it's a SELECT query\n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚ùå 2. Block dangerous operations\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = (\n",
    "            f\"‚ùå Unsafe SQL operation detected. \"\n",
    "            f\"Keywords like {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # ‚úÖ 3. Validate columns used in SQL (prevent hallucinated fields)\n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column name used: '{match}'.\"\n",
    "            return state\n",
    "\n",
    "    # ‚úÖ 4. Passed all checks\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\"‚úÖ SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "def duckdb_node(state: dict):\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL with SQLGlot before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        # üß† Step 1: Ask LLM to generate SQL\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # üßπ Step 2: Clean LLM formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüß† Generated SQL query:\\n{sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        # ‚úÖ Step 3: Syntax validation using SQLGlot\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "            print(\"‚úÖ SQLGlot syntax check passed.\")\n",
    "        except Exception as parse_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error detected: {parse_err}\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 4: Custom SQL safety validation\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 5: Safe execution inside a local DuckDB context\n",
    "        try:\n",
    "            with duckdb.connect(db_path) as con:\n",
    "                result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "            \n",
    "        except Exception as exec_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL execution failed: {exec_err}\"\n",
    "            return state\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 6: Convert results to plain text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # ‚úÖ Step 7: Generate human-readable summary\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping rows or making assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def hybrid_node(state: dict):\n",
    "    \"\"\"Handles hybrid queries (numeric + semantic), distinguishes dependent vs independent sub-questions.\"\"\"\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "        # 1Ô∏è‚É£ Improved split prompt ‚Äî includes automatic Client Name addition for dependent queries\n",
    "        split_prompt = f\"\"\"\n",
    "            You are a **query-splitting assistant** for a hybrid SQL-semantic system.\n",
    "\n",
    "            Your job is to analyze a user's natural-language question and split it into:\n",
    "            - \"numeric\": SQL-based reasoning (e.g., count, sum, max, total, etc.)\n",
    "            - \"semantic\": descriptive or entity-based reasoning (names, categories, or context)\n",
    "            Also detect whether the two parts are **dependent** (the semantic part depends on numeric output)\n",
    "            or **independent** (can be answered separately).\n",
    "\n",
    "            ---\n",
    "            ‚öôÔ∏è SQL Integration Rules:\n",
    "            - If the query is **dependent**, the SQL generator must combine both numeric & descriptive columns\n",
    "              such as `\"Client Name\"` + `\"Total Price (‚Çπ)\"` (or `\"Product Name\"` + `\"Total Price (‚Çπ)\"`) in a single query.\n",
    "            - For dependent cases, the \"numeric\" sub-question should still focus on measurable value (e.g., ‚Äúhighest total‚Äù),\n",
    "              while the \"semantic\" part should express what entity that value belongs to (e.g., ‚Äúwho made that purchase‚Äù).\n",
    "            - For independent cases, both sub-questions can be treated separately.\n",
    "\n",
    "            ---\n",
    "            ‚úÖ Examples\n",
    "\n",
    "            **Example 1 ‚Äî Dependent**\n",
    "            User: \"Who made the highest purchase and how much was it?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"Find the highest purchase amount and the corresponding client name.\",\n",
    "                \"semantic\": \"Who made that purchase and what was the total price?\",\n",
    "                \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 2 ‚Äî Dependent**\n",
    "            User: \"Which product had the highest total sales and how much revenue did it generate?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"Find the product with the highest total sales and its total revenue.\",\n",
    "                \"semantic\": \"Which product achieved that and what was the total revenue?\",\n",
    "                \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 3 ‚Äî Independent**\n",
    "            User: \"How many orders were placed, and who are the top 5 customers?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"How many orders were placed?\",\n",
    "                \"semantic\": \"Who are the top 5 customers?\",\n",
    "                \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            **Example 4 ‚Äî Independent**\n",
    "            User: \"What is the total revenue and list all product categories?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"What is the total revenue?\",\n",
    "                \"semantic\": \"List all product categories.\",\n",
    "                \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            ---\n",
    "            Now process the following user query and return **valid JSON only** (no text outside JSON):\n",
    "\n",
    "            Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "        import json\n",
    "        try:\n",
    "            split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "            dependent = parsed.get(\"dependent\", False)\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part, semantic_part, dependent = \"\", \"\", False\n",
    "            print(\"‚ö†Ô∏è Invalid JSON in split, skipping.\")\n",
    "\n",
    "        print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "        print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "        print(f\"üîó Dependency detected: {dependent}\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Get numeric answer from DuckDB\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüßÆ NUMERIC RESULT (from SQL):\")\n",
    "            print(numeric_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No numeric part found.\")\n",
    "\n",
    "        # 3Ô∏è‚É£ Get semantic answer (only for independent queries)\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüí¨ SEMANTIC RESULT (from Retriever):\")\n",
    "            print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No semantic part found.\")\n",
    "\n",
    "        # 4Ô∏è‚É£ Validation only for independent queries\n",
    "        if not dependent and numeric_answer and semantic_answer:\n",
    "            validation_prompt = f\"\"\"\n",
    "            The following query is INDEPENDENT.\n",
    "            Check if the semantic result is factually consistent with the numeric SQL result.\n",
    "            Focus on consistency between numbers, names, or facts.\n",
    "\n",
    "            Numeric result:\n",
    "            {numeric_answer}\n",
    "\n",
    "            Semantic result:\n",
    "            {semantic_answer}\n",
    "\n",
    "            Reply only in JSON:\n",
    "            {{\n",
    "                \"is_consistent\": true/false,\n",
    "                \"issues\": \"describe discrepancies briefly\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            validation = llm.invoke(validation_prompt).content.strip()\n",
    "            print(\"\\nüîç Validation result:\", validation)\n",
    "\n",
    "            try:\n",
    "                validation_json = json.loads(validation.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "                consistent = validation_json.get(\"is_consistent\", True)\n",
    "            except:\n",
    "                consistent = True  # fallback\n",
    "\n",
    "            # Retry if inconsistent\n",
    "            if not consistent:\n",
    "                print(\"‚ö†Ô∏è Semantic answer inconsistent with SQL ‚Äî retrying with numeric context...\")\n",
    "                retry_prompt = f\"\"\"\n",
    "                The user asked: {question}\n",
    "\n",
    "                The numeric SQL result says:\n",
    "                {numeric_answer}\n",
    "\n",
    "                The previous semantic answer was:\n",
    "                {semantic_answer}\n",
    "\n",
    "                Please re-generate a consistent, unified answer that aligns with the numeric facts.\n",
    "                \"\"\"\n",
    "                semantic_answer = llm.invoke(retry_prompt).content.strip()\n",
    "                print(\"\\n‚ôªÔ∏è RETRIED SEMANTIC ANSWER:\")\n",
    "                print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚úÖ Dependent query detected ‚Äî skipping consistency validation.\")\n",
    "\n",
    "        # 5Ô∏è‚É£ Combine results\n",
    "        print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight (SQL result):\n",
    "        {numeric_answer or \"None\"}\n",
    "\n",
    "        Semantic insight (retrieved/explained result):\n",
    "        {semantic_answer or \"None\"}\n",
    "\n",
    "        Combine both into one clear, natural, factual answer.\n",
    "        If dependent, describe both name and numeric value together (e.g., ‚ÄúKara Mata made the highest purchase of ‚Çπ4,48,170‚Äù).\n",
    "        \"\"\"\n",
    "        combined_response = llm.invoke(combine_prompt)\n",
    "        final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "        state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        print(f\"You :\",user_input)\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Assistant: Goodbye üëã\")\n",
    "            break\n",
    "\n",
    "        result = app.invoke({\"question\": user_input})\n",
    "        print(f\"Assistant: {result['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d85535",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install ipykernel --update-deps --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0c8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 50 labelled chunks for embeddings.\n",
      "‚úÖ Creating new vector store...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document \n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from sqlglot import parse_one\n",
    "import json\n",
    "\n",
    "# ‚úÖ Step 1: Define paths\n",
    "csv_path = r\"D:\\RAG Task\\Client_Shipment_Orders.csv\"\n",
    "db_path = r\"D:\\RAG Task\\orders.duckdb\"\n",
    "\n",
    "# ‚úÖ Step 2: Create or update database table (runs only once)\n",
    "with duckdb.connect(db_path) as con:\n",
    "    # Create the 'orders' table if not already present\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS orders AS\n",
    "        SELECT * FROM read_csv_auto('{csv_path}');\n",
    "    \"\"\")\n",
    "    # Optional: Refresh data if you've updated CSV\n",
    "    # con.execute(f\"DELETE FROM orders; INSERT INTO orders SELECT * FROM read_csv_auto('{csv_path}');\")\n",
    "\n",
    "# ‚úÖ Step 3: Load DataFrame safely for local use\n",
    "with duckdb.connect(db_path) as con:\n",
    "    df = con.execute(\"SELECT * FROM orders\").fetchdf()\n",
    "\n",
    "# ‚úÖ Step 4: Clean / normalize text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# ‚úÖ Step 5: Define persistent directory for embeddings / Chroma\n",
    "persist_directory = r\"D:\\RAG Task\"\n",
    "\n",
    "sql_system_prompt = \"\"\"\n",
    "You are a SQL expert helping to query a DuckDB table named `orders`.\n",
    "\n",
    "----------------------------------\n",
    "TABLE INFORMATION\n",
    "----------------------------------\n",
    "Table name: orders  \n",
    "Columns and their meanings:\n",
    "- Order ID: Unique identifier for each order (text)\n",
    "- Client Name: Name of the customer who placed the order (text)\n",
    "- Email: Email address of the client (text)\n",
    "- Contact Number: Client's contact phone number (text)\n",
    "- Origin: Source location of the shipment (text)\n",
    "- Destination: Delivery location of the shipment (text)\n",
    "- Product Name: Name of the purchased product (text)\n",
    "- Category: Product category (e.g., Furniture, Decor, Appliances)\n",
    "- Material: Material type of the product (e.g., Wood, Glass, Metal)\n",
    "- Color: Color of the product (text)\n",
    "- Quantity: Number of units ordered (integer)\n",
    "- Unit Price (‚Çπ): Price per unit in INR (numeric)\n",
    "- Total Price (‚Çπ): Total order price in INR (numeric)\n",
    "- Order Date: Date when the order was placed (date)\n",
    "- Delivery Date: Date when the order was delivered (date)\n",
    "- Status: Order status (e.g., Delivered, Pending, Cancelled)\n",
    "\n",
    "----------------------------------\n",
    "SAMPLE DATA\n",
    "----------------------------------\n",
    "ORD0001 | Kara Mata | chelsea75@yahoo.com | 038.830.3017x8206 | Port Mariamouth | Cohenmouth | Wall Art | Decor | Glass | Grey | 15 | 29878 | 448170 | 2025-05-13 | 2025-06-02 | Cancelled  \n",
    "ORD0002 | Jesse Williams | ccasey@barrett.info | (426)505-2355 | Tamaraview | Lake Rickyport | Bed | Furniture | Glass | Brown | 30 | 1507 | 45210 | 2025-10-04 | 2025-11-03 | Cancelled  \n",
    "\n",
    "----------------------------------\n",
    "INSTRUCTIONS\n",
    "----------------------------------\n",
    "1. Generate SQL queries **only** for structured or numeric filters.\n",
    "   Examples:\n",
    "   - Total sales, sum, count, average, quantity, or price-based questions  \n",
    "   - Filtering by columns such as Status, Category, Material, or Color  \n",
    "   - Date-based filters (e.g., orders after 2025-05-01)\n",
    "\n",
    "2. **Do NOT** generate queries based on subjective or descriptive logic\n",
    "   such as reasons for cancellation, customer feedback, or preferences.\n",
    "   These are handled separately by a semantic retriever system.\n",
    "\n",
    "3. Use the correct table name `orders` and column names **exactly as shown**.\n",
    "   Preserve proper case and special characters (e.g., `\"Total Price (‚Çπ)\"`).\n",
    "\n",
    "4. Never hallucinate columns, tables, or calculations that do not exist.\n",
    "\n",
    "5. Return **only** the SQL query ‚Äî no markdown, comments, or explanations.\n",
    "\n",
    "6. **SAFETY RULES ‚Äî STRICTLY ENFORCED**\n",
    "   - Never modify or delete data.\n",
    "   - Do not use or suggest `UPDATE`, `DELETE`, `INSERT`, `DROP`, `TRUNCATE`, or `ALTER`.\n",
    "   - Do not create or alter schemas, indexes, or tables.\n",
    "   - Only allow read-only operations:  \n",
    "     `SELECT`, `WHERE`, `GROUP BY`, `ORDER BY`, `LIMIT`, and aggregate functions (`COUNT`, `SUM`, `AVG`, `MIN`, `MAX`).\n",
    "\n",
    "7. **Case Handling:**  \n",
    "   When matching text values (like product or status), use `LOWER()` to make comparisons case-insensitive.  \n",
    "   Example:  \n",
    "   `WHERE LOWER(\"Product Name\") = LOWER('Toilet Bowl')`\n",
    "\n",
    "8. **Special Handling ‚Äî Highest or Maximum Queries:**  \n",
    "   If the user asks questions like  \n",
    "   *\"Who made the highest purchase?\"*,  \n",
    "   *\"Which client has the largest total?\"*, or  \n",
    "   *\"Top buyer / maximum purchase amount\"*,  \n",
    "   use this pattern to avoid grouping errors:\n",
    "   ```sql\n",
    "   SELECT \"Client Name\", \"Total Price (‚Çπ)\"\n",
    "   FROM orders\n",
    "   WHERE \"Total Price (‚Çπ)\" = (\n",
    "       SELECT MAX(\"Total Price (‚Çπ)\") FROM orders\n",
    "   );\n",
    "\"\"\"\n",
    "\n",
    "#  ROW-WISE LABELLED CHUNK GENERATION\n",
    "def generate_labelled_chunks(csv_path):\n",
    "    \"\"\"Creates labelled text chunks from each row for embeddings.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    chunks = []\n",
    "    for index, row in df.iterrows():\n",
    "        labelled_text = f\"Row ID: {index}\\n\"\n",
    "        for col in df.columns:\n",
    "            labelled_text += f\"{col}: {row[col]}\\n\"\n",
    "        chunks.append(labelled_text.strip())\n",
    "    return df, chunks\n",
    "\n",
    "\n",
    "df, labelled_chunks = generate_labelled_chunks(csv_path)\n",
    "\n",
    "documents = [Document(page_content=chunk) for chunk in labelled_chunks]\n",
    "\n",
    "print(f\"‚úÖ Generated {len(labelled_chunks)} labelled chunks for embeddings.\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "collection_name = \"shipment_orders\"\n",
    "\n",
    "# ‚úÖ Fixed: Check if vector store already exists to prevent crashes\n",
    "if os.path.exists(os.path.join(persist_directory, collection_name)):\n",
    "    print(\"‚úÖ Loading existing vector store...\")\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ Creating new vector store...\")\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "keyword_retriever = BM25Retriever.from_documents(documents)\n",
    "keyword_retriever.k = 5\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, keyword_retriever],\n",
    "    weights=[0.6, 0.4]\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    intent: str\n",
    "    context: List[str]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def intent_node(state: dict):\n",
    "    \"\"\"Use LLM to classify query intent based on the Orders dataset\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    intent_prompt = f\"\"\"\n",
    "    You are an intent classifier for user questions over an **Orders dataset**.\n",
    "    The table contains the following columns:\n",
    "    Order ID, Client Name, Email, Contact Number, Origin, Destination,\n",
    "    Product Name, Category, Material, Color, Quantity, Unit Price (‚Çπ),\n",
    "    Total Price (‚Çπ), Order Date, Delivery Date, Status.\n",
    "\n",
    "    Classify the intent of the question as one of the following:\n",
    "\n",
    "    1. \"numeric\" ‚Üí if the query involves structured, measurable, or count-based data.\n",
    "       Examples:\n",
    "       - \"How many orders are pending?\"\n",
    "       - \"What is the total sales amount?\"\n",
    "       - \"Show the average unit price.\"\n",
    "       - \"Count the number of clients.\"\n",
    "       - \"List orders where quantity > 10.\n",
    "       - \"Who made the highest purchase?\"\n",
    "       - \"names of customers who ordered bed \"\n",
    "\n",
    "    2. \"semantic\" ‚Üí if the query involves descriptive or text-based attributes\n",
    "       such true semantic questions, i.e., ones that are descriptive, interpretive, or text-based, not solvable with SQL filters or numbers.\n",
    "T       These rely on understanding meaning, patterns, or unstructured context rather than column values.\n",
    "       Examples:\n",
    "      - Which customers look like regular buyers of furniture?\n",
    "      - Which products are most suitable for modern homes?\n",
    "      - What type of products are popular in Port Mariamouth?\n",
    "      \n",
    "    3. \"hybrid\" ‚Üí if the query mixes both numeric and descriptive components.\n",
    "       Examples:\n",
    "       - What is the total count of clients who bought curtains and Which destination cities frequently receive d√©cor orders?? \n",
    "\n",
    "    4. \"greet\" ‚Üí greetings or conversational openers.\n",
    "       Examples:\n",
    "       - \"Hi\", \"Hello\", \"Good morning\", \"Hey there\"\n",
    "\n",
    "    5. \"ignore\" ‚Üí unrelated or irrelevant to order data.\n",
    "       Examples:\n",
    "       - \"Tell me a joke\", \"What's the time?\", \"Who is the CEO?\"\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Return only one word:\n",
    "    numeric, semantic, hybrid, greet, or ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    intent = llm.invoke(intent_prompt).content.strip().lower()\n",
    "    print(f\"üéØ Detected Intent: {intent}\")\n",
    "    state[\"intent\"] = intent\n",
    "    return state\n",
    "\n",
    "\n",
    "def greet_node(state: dict):\n",
    "    state[\"answer\"] = \"Hello üëã! How can I assist you with the order data today?\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def ignore_node(state: dict):\n",
    "    state[\"answer\"] = \"I'm designed to answer questions about the order dataset. Please ask something related.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def retriever_node(state: dict):\n",
    "    question = state[\"question\"]\n",
    "    try:\n",
    "        retrieved_chunks = hybrid_retriever.invoke(question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in retrieved_chunks])\n",
    "        prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer briefly:\"\n",
    "        answer = llm.invoke(prompt).content.strip()\n",
    "       \n",
    "        state[\"answer\"] = answer\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error using retriever: {e}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "VALID_COLUMNS = [\n",
    "    \"Order ID\", \"Client Name\", \"Email\", \"Contact Number\",\n",
    "    \"Origin\", \"Destination\", \"Product Name\", \"Category\",\n",
    "    \"Material\", \"Color\", \"Quantity\", \"Unit Price (‚Çπ)\",\n",
    "    \"Total Price (‚Çπ)\", \"Order Date\", \"Delivery Date\", \"Status\"\n",
    "]\n",
    "\n",
    "def sql_validator_node(state: dict):\n",
    "    \"\"\"Validates generated SQL to ensure it's safe and valid for DuckDB execution\"\"\"\n",
    "    sql_query = state.get(\"sql_query\", \"\").strip()\n",
    "    print(f\"üß© Validating SQL query: {sql_query}\")\n",
    "\n",
    "    # ‚úÖ 1. Ensure it's a SELECT query\n",
    "    if not sql_query.lower().startswith(\"select\"):\n",
    "        state[\"validation_error\"] = \"‚ùå Only SELECT queries are allowed.\"\n",
    "        return state\n",
    "\n",
    "    # ‚ùå 2. Block dangerous operations\n",
    "    forbidden_keywords = [\"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\"]\n",
    "    if any(kw in sql_query.lower() for kw in forbidden_keywords):\n",
    "        state[\"validation_error\"] = (\n",
    "            f\"‚ùå Unsafe SQL operation detected. \"\n",
    "            f\"Keywords like {', '.join(forbidden_keywords)} are not allowed.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # ‚úÖ 3. Validate columns used in SQL (prevent hallucinated fields)\n",
    "    for match in re.findall(r'\"(.*?)\"', sql_query):\n",
    "        if match not in VALID_COLUMNS:\n",
    "            state[\"validation_error\"] = f\"‚ùå Invalid column name used: '{match}'.\"\n",
    "            return state\n",
    "\n",
    "    # ‚úÖ 4. Passed all checks\n",
    "    state[\"validation_error\"] = None\n",
    "    print(\"‚úÖ SQL validation passed.\")\n",
    "    return state\n",
    "\n",
    "def duckdb_node(state: dict):\n",
    "    \"\"\"Handles numeric/structured questions ‚Äî validates SQL with SQLGlot before executing\"\"\"\n",
    "    query = state[\"question\"]\n",
    "\n",
    "    try:\n",
    "        # üß† Step 1: Ask LLM to generate SQL\n",
    "        sql_prompt = f\"{sql_system_prompt}\\nUser question: {query}\\nSQL:\"\n",
    "        sql_query = llm.invoke(sql_prompt).content.strip()\n",
    "\n",
    "        # üßπ Step 2: Clean LLM formatting\n",
    "        sql_query = (\n",
    "            sql_query.replace(\"```sql\", \"\")\n",
    "                     .replace(\"```\", \"\")\n",
    "                     .replace(\"`\", \"\")\n",
    "                     .replace(\"SQL:\", \"\")\n",
    "                     .strip()\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüß† Generated SQL query:\\n{sql_query}\")\n",
    "        state[\"sql_query\"] = sql_query\n",
    "\n",
    "        # ‚úÖ Step 3: Syntax validation using SQLGlot\n",
    "        try:\n",
    "            parse_one(sql_query)\n",
    "            print(\"‚úÖ SQLGlot syntax check passed.\")\n",
    "        except Exception as parse_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL syntax error detected: {parse_err}\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 4: Custom SQL safety validation\n",
    "        validation_state = sql_validator_node(state)\n",
    "        if validation_state.get(\"validation_error\"):\n",
    "            state[\"answer\"] = validation_state[\"validation_error\"]\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 5: Safe execution inside a local DuckDB context with timeout config\n",
    "        try:\n",
    "            with duckdb.connect(db_path, config={'temp_directory': r'D:\\RAG Task\\temp'}) as con:\n",
    "                result_df = con.execute(sql_query).fetchdf()\n",
    "\n",
    "        except Exception as exec_err:\n",
    "            state[\"answer\"] = f\"‚ö†Ô∏è SQL execution failed: {exec_err}\"\n",
    "            return state\n",
    "\n",
    "        if result_df.empty:\n",
    "            state[\"answer\"] = \"No matching records found.\"\n",
    "            return state\n",
    "\n",
    "        # ‚úÖ Step 6: Convert results to plain text\n",
    "        result_text = result_df.to_string(index=False)\n",
    "\n",
    "        # ‚úÖ Step 7: Generate human-readable summary\n",
    "        summary_prompt = f\"\"\"\n",
    "        The user asked: {query}\n",
    "        The SQL result is:\n",
    "        {result_text}\n",
    "\n",
    "        Write a natural, clear explanation of these results.\n",
    "        Avoid skipping rows or making assumptions.\n",
    "        \"\"\"\n",
    "        answer = llm.invoke(summary_prompt).content.strip()\n",
    "        state[\"answer\"] = answer\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"answer\"] = f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "def hybrid_node(state: dict):\n",
    "    \"\"\"Handles hybrid queries (numeric + semantic), distinguishes dependent vs independent sub-questions.\"\"\"\n",
    "    try:\n",
    "        question = state[\"question\"]\n",
    "        print(f\"\\nüîÄ [Hybrid Node] Received question ‚Üí {question}\")\n",
    "\n",
    "        # 1Ô∏è‚É£ Improved split prompt ‚Äî includes automatic Client Name addition for dependent queries\n",
    "        split_prompt = f\"\"\"\n",
    "            You are a **query-splitting assistant** for a hybrid SQL-semantic system.\n",
    "\n",
    "            Your job is to analyze a user's natural-language question and split it into:\n",
    "            - \"numeric\": SQL-based reasoning (e.g., count, sum, max, total, etc.)\n",
    "            - \"semantic\": descriptive or entity-based reasoning (names, categories, or context)\n",
    "            Also detect whether the two parts are **dependent** (the semantic part depends on numeric output)\n",
    "            or **independent** (can be answered separately).\n",
    "\n",
    "            ---\n",
    "            ‚öôÔ∏è SQL Integration Rules:\n",
    "            - If the query is **dependent**, the SQL generator must combine both numeric & descriptive columns\n",
    "              such as `\"Client Name\"` + `\"Total Price (‚Çπ)\"` (or `\"Product Name\"` + `\"Total Price (‚Çπ)\"`) in a single query.\n",
    "            - For dependent cases, the \"numeric\" sub-question should still focus on measurable value (e.g., \"highest total\"),\n",
    "              while the \"semantic\" part should express what entity that value belongs to (e.g., \"who made that purchase\").\n",
    "            - For independent cases, both sub-questions can be treated separately.\n",
    "\n",
    "            ---\n",
    "            ‚úÖ Examples\n",
    "\n",
    "            **Example 1 ‚Äî Dependent**\n",
    "            User: \"Who made the highest purchase and how much was it?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"Find the highest purchase amount and the corresponding client name.\",\n",
    "                \"semantic\": \"Who made that purchase and what was the total price?\",\n",
    "                \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 2 ‚Äî Dependent**\n",
    "            User: \"Which product had the highest total sales and how much revenue did it generate?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"Find the product with the highest total sales and its total revenue.\",\n",
    "                \"semantic\": \"Which product achieved that and what was the total revenue?\",\n",
    "                \"dependent\": true\n",
    "            }}\n",
    "\n",
    "            **Example 3 ‚Äî Independent**\n",
    "            User: \"How many orders were placed, and who are the top 5 customers?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"How many orders were placed?\",\n",
    "                \"semantic\": \"Who are the top 5 customers?\",\n",
    "                \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            **Example 4 ‚Äî Independent**\n",
    "            User: \"What is the total revenue and list all product categories?\"\n",
    "            Output:\n",
    "            {{\n",
    "                \"numeric\": \"What is the total revenue?\",\n",
    "                \"semantic\": \"List all product categories.\",\n",
    "                \"dependent\": false\n",
    "            }}\n",
    "\n",
    "            ---\n",
    "            Now process the following user query and return **valid JSON only** (no text outside JSON):\n",
    "\n",
    "            Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        split_result = llm.invoke(split_prompt).content.strip()\n",
    "        print(\"üß© Raw Split Result:\", split_result)\n",
    "\n",
    "        try:\n",
    "            split_result = split_result.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            parsed = json.loads(split_result)\n",
    "            numeric_part = parsed.get(\"numeric\", \"\").strip()\n",
    "            semantic_part = parsed.get(\"semantic\", \"\").strip()\n",
    "            dependent = parsed.get(\"dependent\", False)\n",
    "        except json.JSONDecodeError:\n",
    "            numeric_part, semantic_part, dependent = \"\", \"\", False\n",
    "            print(\"‚ö†Ô∏è Invalid JSON in split, skipping.\")\n",
    "\n",
    "        print(f\"‚úÖ Parsed numeric part: {numeric_part}\")\n",
    "        print(f\"‚úÖ Parsed semantic part: {semantic_part}\")\n",
    "        print(f\"üîó Dependency detected: {dependent}\")\n",
    "\n",
    "        # 2Ô∏è‚É£ Get numeric answer from DuckDB\n",
    "        numeric_answer = \"\"\n",
    "        if numeric_part:\n",
    "            temp_state = {\"question\": numeric_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            numeric_state = duckdb_node(temp_state)\n",
    "            numeric_answer = numeric_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüßÆ NUMERIC RESULT (from SQL):\")\n",
    "            print(numeric_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No numeric part found.\")\n",
    "\n",
    "        # 3Ô∏è‚É£ Get semantic answer (only for independent queries)\n",
    "        semantic_answer = \"\"\n",
    "        if semantic_part:\n",
    "            temp_state = {\"question\": semantic_part, \"intent\": \"\", \"context\": [], \"answer\": \"\"}\n",
    "            semantic_state = retriever_node(temp_state)\n",
    "            semantic_answer = semantic_state.get(\"answer\", \"\")\n",
    "            print(\"\\nüí¨ SEMANTIC RESULT (from Retriever):\")\n",
    "            print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No semantic part found.\")\n",
    "\n",
    "        # 4Ô∏è‚É£ Validation only for independent queries\n",
    "        if not dependent and numeric_answer and semantic_answer:\n",
    "            validation_prompt = f\"\"\"\n",
    "            The following query is INDEPENDENT.\n",
    "            Check if the semantic result is factually consistent with the numeric SQL result.\n",
    "            Focus on consistency between numbers, names, or facts.\n",
    "\n",
    "            Numeric result:\n",
    "            {numeric_answer}\n",
    "\n",
    "            Semantic result:\n",
    "            {semantic_answer}\n",
    "\n",
    "            Reply only in JSON:\n",
    "            {{\n",
    "                \"is_consistent\": true/false,\n",
    "                \"issues\": \"describe discrepancies briefly\"\n",
    "            }}\n",
    "            \"\"\"\n",
    "            validation = llm.invoke(validation_prompt).content.strip()\n",
    "            print(\"\\nüîç Validation result:\", validation)\n",
    "\n",
    "            try:\n",
    "                validation_json = json.loads(validation.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "                consistent = validation_json.get(\"is_consistent\", True)\n",
    "            except:\n",
    "                consistent = True  # fallback\n",
    "\n",
    "            # Retry if inconsistent\n",
    "            if not consistent:\n",
    "                print(\"‚ö†Ô∏è Semantic answer inconsistent with SQL ‚Äî retrying with numeric context...\")\n",
    "                retry_prompt = f\"\"\"\n",
    "                The user asked: {question}\n",
    "\n",
    "                The numeric SQL result says:\n",
    "                {numeric_answer}\n",
    "\n",
    "                The previous semantic answer was:\n",
    "                {semantic_answer}\n",
    "\n",
    "                Please re-generate a consistent, unified answer that aligns with the numeric facts.\n",
    "                \"\"\"\n",
    "                semantic_answer = llm.invoke(retry_prompt).content.strip()\n",
    "                print(\"\\n‚ôªÔ∏è RETRIED SEMANTIC ANSWER:\")\n",
    "                print(semantic_answer)\n",
    "        else:\n",
    "            print(\"‚úÖ Dependent query detected ‚Äî skipping consistency validation.\")\n",
    "\n",
    "        # 5Ô∏è‚É£ Combine results\n",
    "        print(\"\\nüß† Combining numeric & semantic results...\")\n",
    "        combine_prompt = f\"\"\"\n",
    "        The user originally asked: {question}\n",
    "\n",
    "        Numeric insight (SQL result):\n",
    "        {numeric_answer or \"None\"}\n",
    "\n",
    "        Semantic insight (retrieved/explained result):\n",
    "        {semantic_answer or \"None\"}\n",
    "\n",
    "        Combine both into one clear, natural, factual answer.\n",
    "        If dependent, describe both name and numeric value together (e.g., \"Kara Mata made the highest purchase of ‚Çπ4,48,170\").\n",
    "        \"\"\"\n",
    "        combined_response = llm.invoke(combine_prompt)\n",
    "        final_answer = getattr(combined_response, \"content\", str(combined_response)).strip()\n",
    "\n",
    "        state[\"answer\"] = final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in hybrid_node: {str(e)}\")\n",
    "        state[\"answer\"] = f\"Error in hybrid_node: {str(e)}\"\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"intent\", intent_node)\n",
    "graph.add_node(\"greet\", greet_node)\n",
    "graph.add_node(\"ignore\", ignore_node)\n",
    "graph.add_node(\"duckdb\", duckdb_node)\n",
    "graph.add_node(\"retriever\", retriever_node)\n",
    "graph.add_node(\"hybrid\", hybrid_node)\n",
    "\n",
    "graph.set_entry_point(\"intent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"intent\",\n",
    "    lambda state: state[\"intent\"],\n",
    "    {\n",
    "        \"greet\": \"greet\",\n",
    "        \"ignore\": \"ignore\",\n",
    "        \"numeric\": \"duckdb\",\n",
    "        \"semantic\": \"retriever\",\n",
    "        \"hybrid\": \"hybrid\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"greet\", END)\n",
    "graph.add_edge(\"ignore\", END)\n",
    "graph.add_edge(\"duckdb\", END)\n",
    "graph.add_edge(\"retriever\", END)\n",
    "graph.add_edge(\"hybrid\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Smart Query Assistant ready! Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \").strip()\n",
    "            print(f\"You: {user_input}\")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Assistant: Goodbye üëã\")\n",
    "                break\n",
    "\n",
    "            result = app.invoke({\"question\": user_input})\n",
    "            print(f\"Assistant: {result['answer']}\\n\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistant: Goodbye üëã\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            print(\"Please try again with a different question.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
